{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":91723,"databundleVersionId":14272474},{"sourceType":"datasetVersion","sourceId":14046080,"datasetId":8931648,"databundleVersionId":14824993}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Logistic regression submission\n\nTo run on Kaggle this notebook needs two inputs:\n1. My [Diabetes prediction challenge: logistic regression](https://www.kaggle.com/datasets/gperdrizet/diabetes-prediction-challenge-logistic-regression) dataset\n2. The [Diabetes prediction challenge](https://www.kaggle.com/competitions/playground-series-s5e12) dataset\n\nThe `Diabetes prediction challenge: logistic regression` dataset contains the Scikit-learn model pipeline, serialized with joblib and a Python module containing the custom transformers used in the pipeline. Once those sources are attached, set the `KAGGLE` flag below to True and run.\n\nTo run from a clone of the [diabetes-prediction](https://github.com/gperdrizet/diabetes-prediction) GitHub repo in any other environment, simply set `KAGGLE` to False.\n\n## Notebook set up\n\n### Imports","metadata":{}},{"cell_type":"code","source":"# Standard library imports\nimport subprocess\nimport sys\nimport urllib.request\nfrom pathlib import Path\n\n# Third party imports\nimport joblib\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:44:39.002339Z","iopub.execute_input":"2025-12-07T15:44:39.002584Z","iopub.status.idle":"2025-12-07T15:44:39.461299Z","shell.execute_reply.started":"2025-12-07T15:44:39.002562Z","shell.execute_reply":"2025-12-07T15:44:39.458146Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Run configuration","metadata":{}},{"cell_type":"code","source":"# Flag to control environment-specific paths & configurations\nKAGGLE = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:44:39.462301Z","iopub.execute_input":"2025-12-07T15:44:39.465142Z","iopub.status.idle":"2025-12-07T15:44:39.475149Z","shell.execute_reply.started":"2025-12-07T15:44:39.465106Z","shell.execute_reply":"2025-12-07T15:44:39.471299Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Add custom transformers to path","metadata":{}},{"cell_type":"code","source":"# Add path to custom transformers module\nif KAGGLE:\n    # On Kaggle, the transformers file should be uploaded as part of the dataset\n    transformers_path = Path('/kaggle/input/diabetes-challenge-logistic-regression-assets')\n\nelse:\n    # For local/GitHub, use the models directory\n    transformers_path = Path('../models').resolve()\n\nsys.path.insert(0, str(transformers_path))\n\n# Import custom transformers (needed for model deserialization)\nfrom logistic_regression_transformers import IDColumnDropper, IQRClipper, ConstantFeatureRemover","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:44:39.476236Z","iopub.execute_input":"2025-12-07T15:44:39.476608Z","iopub.status.idle":"2025-12-07T15:44:40.155395Z","shell.execute_reply.started":"2025-12-07T15:44:39.476581Z","shell.execute_reply":"2025-12-07T15:44:40.154226Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 1. Asset loading","metadata":{}},{"cell_type":"code","source":"# Set file paths based on environment\nif KAGGLE:\n    # Kaggle paths - data is in /kaggle/input/\n    test_df_path = '/kaggle/input/playground-series-s5e12/test.csv'\n    model_path = '/kaggle/input/diabetes-challenge-logistic-regression-assets/logistic_regression.joblib'\n\nelse:\n    # Otherwise, load from GitHub\n    test_df_path = 'https://gperdrizet.github.io/FSA_devops/assets/data/unit3/diabetes_prediction_test.csv'\n    model_url = 'https://github.com/gperdrizet/diabetes-prediction/raw/refs/heads/main/models/logistic_regression.joblib'\n    \n    # Download model to temporary location\n    model_path = Path('logistic_regression.joblib')\n    urllib.request.urlretrieve(model_url, model_path)\n\n# Load the testing dataset\ntest_df = pd.read_csv(test_df_path)\n\n# Load the model\nmodel = joblib.load(model_path)\n\n# Display first few rows of training data\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:44:40.156465Z","iopub.execute_input":"2025-12-07T15:44:40.156877Z","iopub.status.idle":"2025-12-07T15:44:41.423949Z","shell.execute_reply.started":"2025-12-07T15:44:40.156853Z","shell.execute_reply":"2025-12-07T15:44:41.422999Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       id  age  alcohol_consumption_per_week  \\\n0  700000   45                             4   \n1  700001   35                             1   \n2  700002   45                             1   \n3  700003   55                             2   \n4  700004   77                             2   \n\n   physical_activity_minutes_per_week  diet_score  sleep_hours_per_day  \\\n0                                 100         4.3                  6.8   \n1                                  87         3.5                  4.6   \n2                                  61         7.6                  6.8   \n3                                  81         7.3                  7.3   \n4                                  29         7.3                  7.6   \n\n   screen_time_hours_per_day   bmi  waist_to_hip_ratio  systolic_bp  ...  \\\n0                        6.2  25.5                0.84          123  ...   \n1                        9.0  28.6                0.88          120  ...   \n2                        7.0  28.5                0.94          112  ...   \n3                        5.0  26.9                0.91          114  ...   \n4                        8.5  22.0                0.83          131  ...   \n\n   triglycerides  gender  ethnicity  education_level  income_level  \\\n0            111  Female      White       Highschool        Middle   \n1            145  Female      White       Highschool        Middle   \n2            184    Male      White       Highschool           Low   \n3            128    Male      White         Graduate        Middle   \n4            133    Male      White         Graduate           Low   \n\n   smoking_status employment_status family_history_diabetes  \\\n0          Former          Employed                       0   \n1           Never        Unemployed                       0   \n2           Never          Employed                       0   \n3          Former          Employed                       0   \n4         Current        Unemployed                       0   \n\n  hypertension_history cardiovascular_history  \n0                    0                      0  \n1                    0                      0  \n2                    0                      0  \n3                    0                      0  \n4                    0                      0  \n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>alcohol_consumption_per_week</th>\n      <th>physical_activity_minutes_per_week</th>\n      <th>diet_score</th>\n      <th>sleep_hours_per_day</th>\n      <th>screen_time_hours_per_day</th>\n      <th>bmi</th>\n      <th>waist_to_hip_ratio</th>\n      <th>systolic_bp</th>\n      <th>...</th>\n      <th>triglycerides</th>\n      <th>gender</th>\n      <th>ethnicity</th>\n      <th>education_level</th>\n      <th>income_level</th>\n      <th>smoking_status</th>\n      <th>employment_status</th>\n      <th>family_history_diabetes</th>\n      <th>hypertension_history</th>\n      <th>cardiovascular_history</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>700000</td>\n      <td>45</td>\n      <td>4</td>\n      <td>100</td>\n      <td>4.3</td>\n      <td>6.8</td>\n      <td>6.2</td>\n      <td>25.5</td>\n      <td>0.84</td>\n      <td>123</td>\n      <td>...</td>\n      <td>111</td>\n      <td>Female</td>\n      <td>White</td>\n      <td>Highschool</td>\n      <td>Middle</td>\n      <td>Former</td>\n      <td>Employed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>700001</td>\n      <td>35</td>\n      <td>1</td>\n      <td>87</td>\n      <td>3.5</td>\n      <td>4.6</td>\n      <td>9.0</td>\n      <td>28.6</td>\n      <td>0.88</td>\n      <td>120</td>\n      <td>...</td>\n      <td>145</td>\n      <td>Female</td>\n      <td>White</td>\n      <td>Highschool</td>\n      <td>Middle</td>\n      <td>Never</td>\n      <td>Unemployed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>700002</td>\n      <td>45</td>\n      <td>1</td>\n      <td>61</td>\n      <td>7.6</td>\n      <td>6.8</td>\n      <td>7.0</td>\n      <td>28.5</td>\n      <td>0.94</td>\n      <td>112</td>\n      <td>...</td>\n      <td>184</td>\n      <td>Male</td>\n      <td>White</td>\n      <td>Highschool</td>\n      <td>Low</td>\n      <td>Never</td>\n      <td>Employed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>700003</td>\n      <td>55</td>\n      <td>2</td>\n      <td>81</td>\n      <td>7.3</td>\n      <td>7.3</td>\n      <td>5.0</td>\n      <td>26.9</td>\n      <td>0.91</td>\n      <td>114</td>\n      <td>...</td>\n      <td>128</td>\n      <td>Male</td>\n      <td>White</td>\n      <td>Graduate</td>\n      <td>Middle</td>\n      <td>Former</td>\n      <td>Employed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>700004</td>\n      <td>77</td>\n      <td>2</td>\n      <td>29</td>\n      <td>7.3</td>\n      <td>7.6</td>\n      <td>8.5</td>\n      <td>22.0</td>\n      <td>0.83</td>\n      <td>131</td>\n      <td>...</td>\n      <td>133</td>\n      <td>Male</td>\n      <td>White</td>\n      <td>Graduate</td>\n      <td>Low</td>\n      <td>Current</td>\n      <td>Unemployed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## 2. Inference","metadata":{}},{"cell_type":"code","source":"predictions_df = pd.DataFrame({\n    'id': test_df['id'].astype(int),\n    'diagnosed_diabetes': model.predict(test_df).astype(int)\n})\n\npredictions_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:44:41.426147Z","iopub.execute_input":"2025-12-07T15:44:41.426521Z","iopub.status.idle":"2025-12-07T15:44:47.940687Z","shell.execute_reply.started":"2025-12-07T15:44:41.426499Z","shell.execute_reply":"2025-12-07T15:44:47.939572Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 300000 entries, 0 to 299999\nData columns (total 2 columns):\n #   Column              Non-Null Count   Dtype\n---  ------              --------------   -----\n 0   id                  300000 non-null  int64\n 1   diagnosed_diabetes  300000 non-null  int64\ndtypes: int64(2)\nmemory usage: 4.6 MB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 3. Save submission file","metadata":{}},{"cell_type":"code","source":"# Set submission file path based on environment\nif KAGGLE:\n    submission_path = Path('submission.csv')\n\nelse:\n    # Create data directory if it doesn't exist\n    data_dir = Path('../data')\n    data_dir.mkdir(parents=True, exist_ok=True)\n    submission_path = data_dir / 'logistic_regression_submission.csv'\n\n# Save submission file\npredictions_df.to_csv(submission_path, index=False)\nprint(f'Submission saved to: {submission_path}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:44:47.941909Z","iopub.execute_input":"2025-12-07T15:44:47.942334Z","iopub.status.idle":"2025-12-07T15:44:48.183114Z","shell.execute_reply.started":"2025-12-07T15:44:47.942301Z","shell.execute_reply":"2025-12-07T15:44:48.182095Z"}},"outputs":[{"name":"stdout","text":"Submission saved to: submission.csv\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 4. Clean up","metadata":{}},{"cell_type":"code","source":"# Clean up downloaded model file if not on Kaggle\nif not KAGGLE and model_path.exists():\n    model_path.unlink()\n    print(f'Cleaned up temporary model file: {model_path}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:44:48.184163Z","iopub.execute_input":"2025-12-07T15:44:48.184617Z","iopub.status.idle":"2025-12-07T15:44:48.189803Z","shell.execute_reply.started":"2025-12-07T15:44:48.184583Z","shell.execute_reply":"2025-12-07T15:44:48.188826Z"}},"outputs":[],"execution_count":7}]}