{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216a35b3",
   "metadata": {},
   "source": [
    "## Kaggle Setup Instructions\n",
    "\n",
    "When running on Kaggle, you need to:\n",
    "1. Create a dataset with `logistic_regression.joblib` and `logistic_regression_transformers.py` from the models directory\n",
    "2. Add the dataset to your notebook as an input\n",
    "3. Set `KAGGLE = True` in the run configuration below\n",
    "\n",
    "The custom transformers file is required because the model pipeline uses custom transformers that must be importable when deserializing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6650dca",
   "metadata": {},
   "source": [
    "# Logistic regression submission\n",
    "\n",
    "## Notebook set up\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfcf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sys\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29baca",
   "metadata": {},
   "source": [
    "### Run configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to control file paths for Kaggle vs other environments\n",
    "KAGGLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44afe2",
   "metadata": {},
   "source": [
    "### Add custom transformers to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea7cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path to custom transformers module\n",
    "if KAGGLE:\n",
    "    # On Kaggle, the transformers file should be uploaded as part of the dataset\n",
    "    # Add the input directory to the path\n",
    "    transformers_path = Path('/kaggle/input/diabetes-model')\n",
    "else:\n",
    "    # For local/GitHub, use the models directory\n",
    "    transformers_path = Path('../models').resolve()\n",
    "\n",
    "sys.path.insert(0, str(transformers_path))\n",
    "\n",
    "# Import custom transformers\n",
    "from logistic_regression_transformers import IDColumnDropper, IQRClipper, ConstantFeatureRemover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846ea9e",
   "metadata": {},
   "source": [
    "## 1. Asset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea464f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths based on environment\n",
    "if KAGGLE:\n",
    "\n",
    "    # Kaggle paths - data is in /kaggle/input/\n",
    "    test_df_path = '/kaggle/input/playground-series-s5e12/test.csv'\n",
    "    model_path = '/kaggle/input/diabetes-model/logistic_regression.joblib'\n",
    "else:\n",
    "\n",
    "    # Otherwise, load from GitHub\n",
    "    test_df_path = 'https://gperdrizet.github.io/FSA_devops/assets/data/unit3/diabetes_prediction_test.csv'\n",
    "    model_url = 'https://github.com/gperdrizet/diabetes-prediction/raw/refs/heads/main/models/logistic_regression.joblib'\n",
    "    \n",
    "    # Download model to temporary location\n",
    "    model_path = Path('logistic_regression.joblib')\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "\n",
    "# Load the testing dataset\n",
    "test_df = pd.read_csv(test_df_path)\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# Display first few rows of training data\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b1c42",
   "metadata": {},
   "source": [
    "## 2. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'id': test_df['id'].astype(int),\n",
    "    'diagnosed_diabetes': model.predict(test_df).astype(int)\n",
    "})\n",
    "\n",
    "predictions_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad98fcf",
   "metadata": {},
   "source": [
    "## 3. Save submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set submission file path based on environment\n",
    "if KAGGLE:\n",
    "    submission_path = Path('submission.csv')\n",
    "\n",
    "else:\n",
    "    # Create data directory if it doesn't exist\n",
    "    data_dir = Path('../data')\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    submission_path = data_dir / 'logistic_regression_submission.csv'\n",
    "\n",
    "# Save submission file\n",
    "predictions_df.to_csv(submission_path, index=False)\n",
    "print(f'Submission saved to: {submission_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ed428",
   "metadata": {},
   "source": [
    "## 4. Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up downloaded model file if not on Kaggle\n",
    "if not KAGGLE and model_path.exists():\n",
    "\n",
    "    model_path.unlink()\n",
    "    print(f'Cleaned up temporary model file: {model_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
