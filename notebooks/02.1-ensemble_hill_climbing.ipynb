{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e07897",
   "metadata": {},
   "source": [
    "## Setup and configuration\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# Tensorflow logging configuration - must set before importing TensorFlow\n",
    "# turns off INFO and WARNING messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Third party imports\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add models directory to path for ensemble_classifier import\n",
    "sys.path.insert(0, str(Path('../models').resolve()))\n",
    "\n",
    "# Import ensemble modules\n",
    "from ensemble_classifier import EnsembleClassifier\n",
    "from functions import ensemble_database\n",
    "from functions.ensemble_initialization import create_data_splits, create_base_preprocessor, train_founder_model\n",
    "from functions.ensemble_parallel import train_single_candidate, prepare_training_batch\n",
    "from functions.ensemble_evaluation import evaluate_candidate_ensemble\n",
    "from functions.ensemble_stage2_training import train_or_expand_stage2_model, save_ensemble_bundle\n",
    "from functions.ensemble_hill_climbing import (\n",
    "    adaptive_simulated_annealing_acceptance,\n",
    "    update_temperature,\n",
    "    log_iteration\n",
    ")\n",
    "\n",
    "from functions.ensemble_stage2_model import save_checkpoint\n",
    "from functions.ensemble_stage2_training import (\n",
    "    generate_pseudo_labels, \n",
    "    augment_training_pool_with_pseudo_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad288de9",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546abb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Set up logging\n",
    "Path('../logs').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'../logs/training.log', mode='w')\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Check GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f'GPUs available: {gpus}')\n",
    "print(f'Number of GPUs: {len(gpus)}')\n",
    "\n",
    "# Check CPUs\n",
    "n_cpus = cpu_count()\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'Available CPUs: {n_cpus}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77467d",
   "metadata": {},
   "source": [
    "### Ensemble training & hill climb parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b2241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "RANDOM_STATE = 315\n",
    "label = 'diagnosed_diabetes'\n",
    "\n",
    "# Parallel training configuration\n",
    "BATCH_SIZE = 20              # Train this many candidates in parallel\n",
    "N_WORKERS = BATCH_SIZE       # Use all available CPUs as workers\n",
    "MODEL_TIMEOUT_MINUTES = 60   # Maximum training time per model (minutes)\n",
    "\n",
    "# Hill climbing configuration\n",
    "MAX_ITERATIONS = 1000\n",
    "PLATEAU_ITERATIONS = 100\n",
    "BASE_TEMPERATURE = 0.0005\n",
    "TEMPERATURE_DECAY = 0.998\n",
    "\n",
    "# Stage 2 DNN configuration\n",
    "STAGE2_BATCH_SIZE_MODELS = 20  # Retrain DNN every N accepted models\n",
    "STAGE2_EPOCHS = 50\n",
    "STAGE2_BATCH_SIZE = 128\n",
    "STAGE2_PATIENCE = 10\n",
    "\n",
    "# Pseudo-labeling configuration\n",
    "PSEUDO_LABEL_ENABLED = True           # Enable pseudo-labeling\n",
    "PSEUDO_CONFIDENCE_THRESHOLD = 0.75    # Only use very confident predictions\n",
    "PSEUDO_MAX_FRACTION = 0.20            # Max 15% of training pool can be pseudo-labeled\n",
    "PSEUDO_BALANCE_CLASSES = False        # Ensure balanced pseudo-labeled samples\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data')\n",
    "MODELS_BASE_DIR = Path('../models')\n",
    "MODELS_DIR = MODELS_BASE_DIR / f'run_{timestamp}'\n",
    "ENSEMBLE_DIR = MODELS_DIR / 'ensemble_stage1_models'\n",
    "CHECKPOINT_PATH = MODELS_DIR / 'ensemble_checkpoint.pkl'\n",
    "\n",
    "# Create directories\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ENSEMBLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'\\nConfiguration:')\n",
    "print(f'  Parallel workers: {N_WORKERS}')\n",
    "print(f'  Batch size: {BATCH_SIZE}')\n",
    "print(f'  Model timeout: {MODEL_TIMEOUT_MINUTES} minutes')\n",
    "print(f'\\nPseudo-labeling:')\n",
    "print(f'  Enabled: {PSEUDO_LABEL_ENABLED}')\n",
    "print(f'  Confidence threshold: {PSEUDO_CONFIDENCE_THRESHOLD}')\n",
    "print(f'  Max fraction: {PSEUDO_MAX_FRACTION * 100:.0f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8897d92",
   "metadata": {},
   "source": [
    "### Initialize progress dashboard database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c236bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_database.reset_database()\n",
    "ensemble_database.init_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d732b6",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df_path = 'https://gperdrizet.github.io/FSA_devops/assets/data/unit3/diabetes_prediction_train.csv'\n",
    "train_df = pd.read_csv(train_df_path)\n",
    "train_df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f'Training data shape: {train_df.shape}\\n')\n",
    "print('Class distribution:')\n",
    "print(train_df['diagnosed_diabetes'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data for pseudo-labeling\n",
    "test_df_path = 'https://gperdrizet.github.io/FSA_devops/assets/data/unit3/diabetes_prediction_test.csv'\n",
    "test_df = pd.read_csv(test_df_path)\n",
    "test_df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f'\\nTest data shape: {test_df.shape}')\n",
    "print('Test data will be used for pseudo-labeling after Stage 2 DNN training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff019cac",
   "metadata": {},
   "source": [
    "### Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'diagnosed_diabetes'\n",
    "\n",
    "numerical_features = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi',\n",
    "    'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate',\n",
    "    'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides',\n",
    "]\n",
    "\n",
    "ordinal_features = ['education_level', 'income_level']\n",
    "education_categories = [['No formal', 'Highschool', 'Graduate', 'Postgraduate']]\n",
    "income_categories = [['Low', 'Lower-Middle', 'Middle', 'Upper-Middle', 'High']]\n",
    "nominal_features = [\n",
    "    'gender', 'ethnicity', 'smoking_status', 'employment_status',\n",
    "    'family_history_diabetes', 'hypertension_history', 'cardiovascular_history'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0e51f",
   "metadata": {},
   "source": [
    "### Trainining-validation-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c44282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fixed three-way data split\n",
    "X_train_pool, X_val_s1, X_val_s2, y_train_pool, y_val_s1, y_val_s2 = create_data_splits(\n",
    "    train_df, label, RANDOM_STATE\n",
    ")\n",
    "\n",
    "print('Data info before batch preparation:')\n",
    "print(f'  X_train_pool: {type(X_train_pool)} - {X_train_pool.shape}')\n",
    "print(f'  X_val_s1: {type(X_val_s1)} - {X_val_s1.shape}')\n",
    "print(f'  X_val_s2: {type(y_val_s2)} - {y_val_s2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7eda43",
   "metadata": {},
   "source": [
    "### Base data preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base preprocessor\n",
    "base_preprocessor = create_base_preprocessor(\n",
    "    numerical_features, ordinal_features, nominal_features,\n",
    "    education_categories, income_categories\n",
    ")\n",
    "\n",
    "base_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd576f7",
   "metadata": {},
   "source": [
    "## Initialize ensemble with founder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73218e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train founder model (baseline only - NOT added to ensemble)\n",
    "founder_auc = train_founder_model(\n",
    "    X_train_pool, X_val_s1, X_val_s2, y_train_pool, y_val_s1, y_val_s2,\n",
    "    base_preprocessor, RANDOM_STATE, BASE_TEMPERATURE, ENSEMBLE_DIR\n",
    ")\n",
    "\n",
    "# Initialize ensemble (EMPTY - founder not included)\n",
    "ensemble_models = []\n",
    "stage2_model = None\n",
    "best_ensemble_score = founder_auc\n",
    "\n",
    "# Initialize hill climbing variables (start at iteration 1, not 0)\n",
    "start_iteration = 1\n",
    "temperature = BASE_TEMPERATURE\n",
    "\n",
    "print(f'\\nFounder baseline AUC: {founder_auc:.4f}')\n",
    "print(f'Ensemble starts empty - first batch will be iterations 1-{BATCH_SIZE}')\n",
    "print(f'Stage 2 DNN will be trained after {STAGE2_BATCH_SIZE_MODELS} accepted models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8df88a",
   "metadata": {},
   "source": [
    "## Parallel hill climbing loop\n",
    "\n",
    "Iteratively trains batches of candidate models in parallel, evaluates with hybrid scoring,\n",
    "and accepts/rejects using simulated annealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1074db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hill climbing loop variables\n",
    "iteration = start_iteration\n",
    "iterations_since_improvement = 0\n",
    "batch_counter = 0  # Track batch number for dashboard\n",
    "\n",
    "logger.info(f'Starting ensemble hill climbing at {datetime.now()}')\n",
    "logger.info(f'Founder baseline: {founder_auc:.4f}')\n",
    "\n",
    "# Main hill climbing loop (batched parallel)\n",
    "while iteration < MAX_ITERATIONS:\n",
    "\n",
    "    logger.info(f'BATCH {batch_counter}: iterations {iteration}-{min(iteration + BATCH_SIZE - 1, MAX_ITERATIONS)} | Ensemble: {len(ensemble_models)} models, Best: {best_ensemble_score:.4f}, Temp: {temperature:.4f}')\n",
    "    \n",
    "    # Prepare batch of training tasks (pass batch_counter for tracking)\n",
    "    batch_tasks = prepare_training_batch(\n",
    "        iteration=iteration,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        max_iterations=MAX_ITERATIONS,\n",
    "        X_train_pool=X_train_pool,\n",
    "        y_train_pool=y_train_pool,\n",
    "        X_val_s1=X_val_s1,\n",
    "        y_val_s1=y_val_s1,\n",
    "        base_preprocessor=base_preprocessor,\n",
    "        random_state=RANDOM_STATE,\n",
    "        total_cpus=N_WORKERS,\n",
    "        timeout_minutes=MODEL_TIMEOUT_MINUTES,\n",
    "        batch_num=batch_counter\n",
    "    )\n",
    "    \n",
    "    # Train candidates in parallel\n",
    "    with ProcessPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    \n",
    "        futures = {\n",
    "            executor.submit(train_single_candidate, task): task[0]\n",
    "            for task in batch_tasks\n",
    "        }\n",
    "        \n",
    "        # Collect results with timeout\n",
    "        results = []\n",
    "        \n",
    "        try:\n",
    "            # Try to collect all results within the timeout\n",
    "            for future in as_completed(futures, timeout=MODEL_TIMEOUT_MINUTES * 60):\n",
    "\n",
    "                try:\n",
    "                    result = future.result(timeout=60)  # 1 minute for result extraction\n",
    "                    results.append(result)\n",
    "\n",
    "                except TimeoutError as e:\n",
    "\n",
    "                    iter_num = futures[future]\n",
    "                    # Note: Model type unknown for timeouts during execution\n",
    "                    logger.error(f'Iteration {iter_num} timed out: {e}')\n",
    "                    results.append({\n",
    "                        'iteration': iter_num,\n",
    "                        'timeout': True,\n",
    "                        'accept': False,\n",
    "                        'reason': 'timeout',\n",
    "                        'fitted_pipeline': None,\n",
    "                        'metadata': {},\n",
    "                        'val_auc_s1': 0.0,\n",
    "                        'candidate_score': 0.0,\n",
    "                        'diversity_score': 0.0,\n",
    "                        'pipeline_hash': 'timeout',\n",
    "                        'training_memory_mb': 0.0,\n",
    "                        'training_time_sec': 0.0,\n",
    "                        'stage2_memory_mb': 0.0,\n",
    "                        'stage2_time_sec': 0.0\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "\n",
    "                    iter_num = futures[future]\n",
    "                    logger.error(f'Iteration {iter_num} failed: {e}')\n",
    "                    results.append({\n",
    "                        'iteration': iter_num,\n",
    "                        'timeout': False,\n",
    "                        'accept': False,\n",
    "                        'reason': 'exception',\n",
    "                        'fitted_pipeline': None,\n",
    "                        'metadata': {},\n",
    "                        'val_auc_s1': 0.0,\n",
    "                        'candidate_score': 0.0,\n",
    "                        'diversity_score': 0.0,\n",
    "                        'pipeline_hash': 'exception',\n",
    "                        'training_memory_mb': 0.0,\n",
    "                        'training_time_sec': 0.0,\n",
    "                        'stage2_memory_mb': 0.0,\n",
    "                        'stage2_time_sec': 0.0\n",
    "                    })\n",
    "        \n",
    "        except TimeoutError:\n",
    "            # as_completed() timed out - some futures didn't finish\n",
    "            logger.error(f'Batch timeout: not all workers completed within {MODEL_TIMEOUT_MINUTES} minutes')\n",
    "            \n",
    "            # Mark any remaining futures as timeout\n",
    "            for future, iter_num in futures.items():\n",
    "                if not future.done():\n",
    "                    logger.error(f'Iteration {iter_num} did not complete')\n",
    "                    results.append({\n",
    "                        'iteration': iter_num,\n",
    "                        'timeout': True,\n",
    "                        'accept': False,\n",
    "                        'reason': 'batch_timeout',\n",
    "                        'fitted_pipeline': None,\n",
    "                        'metadata': {},\n",
    "                        'val_auc_s1': 0.0,\n",
    "                        'candidate_score': 0.0,\n",
    "                        'diversity_score': 0.0,\n",
    "                        'pipeline_hash': 'batch_timeout',\n",
    "                        'training_memory_mb': 0.0,\n",
    "                        'training_time_sec': 0.0,\n",
    "                        'stage2_memory_mb': 0.0,\n",
    "                        'stage2_time_sec': 0.0\n",
    "                    })\n",
    "    \n",
    "    # Sort results by iteration number\n",
    "    results.sort(key=lambda x: x['iteration'])\n",
    "    \n",
    "    # Process results\n",
    "    accepted_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        current_iter = result['iteration']\n",
    "        \n",
    "        # Handle timeout\n",
    "        if result.get('timeout', False):\n",
    "            # Log timeout entry\n",
    "            log_iteration(\n",
    "                iteration=current_iter,\n",
    "                accepted=False,\n",
    "                rejection_reason='timeout',\n",
    "                pipeline_hash='timeout',\n",
    "                stage1_val_auc=0.0,\n",
    "                stage2_val_auc=0.0,\n",
    "                ensemble_size=len(ensemble_models),\n",
    "                diversity_score=0.0,\n",
    "                temperature=temperature,\n",
    "                metadata={'classifier_type': 'timeout', 'transformers_used': []},\n",
    "                ensemble_id=f'iter_{current_iter}',\n",
    "                timeout=True\n",
    "            )\n",
    "\n",
    "            continue\n",
    "        \n",
    "        # Handle other exceptions\n",
    "        if result.get('fitted_pipeline', None) is None:\n",
    "            # Log exception entry\n",
    "            log_iteration(\n",
    "                iteration=current_iter,\n",
    "                accepted=False,\n",
    "                rejection_reason='exception',\n",
    "                pipeline_hash='exception',\n",
    "                stage1_val_auc=0.0,\n",
    "                stage2_val_auc=0.0,\n",
    "                ensemble_size=len(ensemble_models),\n",
    "                diversity_score=0.0,\n",
    "                temperature=temperature,\n",
    "                metadata={'classifier_type': 'exception', 'transformers_used': []},\n",
    "                ensemble_id=f'iter_{current_iter}',\n",
    "                timeout=False\n",
    "            )\n",
    "\n",
    "            continue\n",
    "        \n",
    "        # Extract basic results from training\n",
    "        fitted_pipeline = result['fitted_pipeline']\n",
    "        metadata = result['metadata']\n",
    "        val_auc_s1 = result['val_auc_s1']\n",
    "        pipeline_hash = result['pipeline_hash']\n",
    "        training_memory_mb = result['memory_mb']\n",
    "        training_time_sec = result['training_time_sec']\n",
    "        \n",
    "        # Create candidate ensemble (current ensemble + new candidate)\n",
    "        candidate_ensemble = ensemble_models + [fitted_pipeline]\n",
    "        \n",
    "        # Evaluate the candidate using the ensemble evaluation logic\n",
    "        candidate_score, diversity_score, aggregation_method = evaluate_candidate_ensemble(\n",
    "            candidate_ensemble=candidate_ensemble,\n",
    "            ensemble_models=ensemble_models,\n",
    "            stage2_model=stage2_model,\n",
    "            X_val_s1=X_val_s1,\n",
    "            X_val_s2=X_val_s2,\n",
    "            y_val_s1=y_val_s1,\n",
    "            y_val_s2=y_val_s2\n",
    "        )\n",
    "        \n",
    "        # Apply simulated annealing acceptance criterion\n",
    "        accept, reason = adaptive_simulated_annealing_acceptance(\n",
    "            current_score=best_ensemble_score,\n",
    "            candidate_score=candidate_score,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        stage2_memory_mb = 0.0\n",
    "        stage2_time_sec = 0.0\n",
    "        \n",
    "        # Determine logged score for database\n",
    "        logged_ensemble_score = candidate_score if accept else best_ensemble_score\n",
    "        \n",
    "        # Log to database\n",
    "        log_iteration(\n",
    "            iteration=current_iter,\n",
    "            accepted=accept,\n",
    "            rejection_reason=reason,\n",
    "            pipeline_hash=pipeline_hash,\n",
    "            stage1_val_auc=val_auc_s1,\n",
    "            stage2_val_auc=logged_ensemble_score,\n",
    "            ensemble_size=len(ensemble_models) + 1 if accept else len(ensemble_models),\n",
    "            diversity_score=diversity_score,\n",
    "            temperature=temperature,\n",
    "            metadata=metadata,\n",
    "            ensemble_id=f'iter_{current_iter}',\n",
    "            training_memory_mb=training_memory_mb,\n",
    "            stage2_memory_mb=stage2_memory_mb,\n",
    "            training_time_sec=training_time_sec,\n",
    "            stage2_time_sec=stage2_time_sec,\n",
    "            timeout=False\n",
    "        )\n",
    "        \n",
    "        # Update ensemble if accepted\n",
    "        if accept:\n",
    "            accepted_count += 1\n",
    "            ensemble_models.append(fitted_pipeline)\n",
    "            \n",
    "            # Save model\n",
    "            model_path = ENSEMBLE_DIR / f'model_{current_iter}.joblib'\n",
    "            joblib.dump(fitted_pipeline, model_path)\n",
    "            \n",
    "            # Check if we should train/retrain stage 2 DNN\n",
    "            if len(ensemble_models) % STAGE2_BATCH_SIZE_MODELS == 0 and len(ensemble_models) > 0:\n",
    "                stage2_model, final_score, stage2_memory_mb, stage2_time_sec, stage2_tp, stage2_fp, stage2_tn, stage2_fn = train_or_expand_stage2_model(\n",
    "                    ensemble_models, stage2_model, X_val_s1, y_val_s1, X_val_s2, y_val_s2,\n",
    "                    STAGE2_EPOCHS, STAGE2_BATCH_SIZE, STAGE2_PATIENCE, current_iter\n",
    "                )\n",
    "                \n",
    "                # Log DNN retrain\n",
    "                logger.info(f'DNN RETRAINED at {len(ensemble_models)} models | Final ensemble AUC: {final_score:.6f}')\n",
    "                \n",
    "                # PSEUDO-LABELING: Generate and augment training pool\n",
    "                if PSEUDO_LABEL_ENABLED and stage2_model is not None:\n",
    "                    \n",
    "                    # Generate pseudo-labels from test set\n",
    "                    X_pseudo, y_pseudo, pseudo_stats = generate_pseudo_labels(\n",
    "                        ensemble_models=ensemble_models,\n",
    "                        stage2_model=stage2_model,\n",
    "                        test_df=test_df,\n",
    "                        confidence_threshold=PSEUDO_CONFIDENCE_THRESHOLD,\n",
    "                        balance_classes=PSEUDO_BALANCE_CLASSES\n",
    "                    )\n",
    "                    \n",
    "                    # Augment training pool if we got pseudo-labels\n",
    "                    if len(X_pseudo) > 0:\n",
    "                        X_train_pool, y_train_pool, aug_stats = augment_training_pool_with_pseudo_labels(\n",
    "                            X_train_pool=X_train_pool,\n",
    "                            y_train_pool=y_train_pool,\n",
    "                            X_pseudo=X_pseudo,\n",
    "                            y_pseudo=y_pseudo,\n",
    "                            max_pseudo_fraction=PSEUDO_MAX_FRACTION\n",
    "                        )\n",
    "                \n",
    "                print(f'DNN RETRAINED at {len(ensemble_models)} models | Final AUC: {final_score:.6f}')\n",
    "                print(f'  Memory: {stage2_memory_mb:.1f}MB, Time: {stage2_time_sec:.1f}s')\n",
    "                \n",
    "                if PSEUDO_LABEL_ENABLED and stage2_model is not None and len(X_pseudo) > 0:\n",
    "                    print(f'  Pseudo-labeled: +{aug_stats[\"pseudo_size\"]:,} samples, Pool now {aug_stats[\"augmented_size\"]:,}')\n",
    "                \n",
    "                log_iteration(\n",
    "                    iteration=current_iter,\n",
    "                    accepted=True,\n",
    "                    rejection_reason=f'dnn_retrain_batch_{len(ensemble_models)}',\n",
    "                    pipeline_hash=f\"dnn_retrain_{len(ensemble_models)}\",\n",
    "                    stage1_val_auc=val_auc_s1,\n",
    "                    stage2_val_auc=final_score,\n",
    "                    ensemble_size=len(ensemble_models),\n",
    "                    diversity_score=diversity_score,\n",
    "                    temperature=temperature,\n",
    "                    metadata={'classifier_type': 'dnn_retrain', 'transformers_used': []},\n",
    "                    ensemble_id=f'dnn_retrain_{len(ensemble_models)}',\n",
    "                    training_memory_mb=None,\n",
    "                    stage2_memory_mb=stage2_memory_mb,\n",
    "                    training_time_sec=None,\n",
    "                    stage2_time_sec=stage2_time_sec,\n",
    "                    timeout=False,\n",
    "                    stage2_tp=stage2_tp,\n",
    "                    stage2_fp=stage2_fp,\n",
    "                    stage2_tn=stage2_tn,\n",
    "                    stage2_fn=stage2_fn\n",
    "                )\n",
    "                \n",
    "                # Save ensemble bundle checkpoint\n",
    "                save_ensemble_bundle(\n",
    "                    ensemble_models, stage2_model, final_score, current_iter,\n",
    "                    MODELS_DIR, RANDOM_STATE, BATCH_SIZE, N_WORKERS, base_preprocessor,\n",
    "                    numerical_features, ordinal_features, nominal_features,\n",
    "                    education_categories, income_categories\n",
    "                )\n",
    "                \n",
    "                # Update best_ensemble_score after DNN retrain\n",
    "                best_ensemble_score = final_score\n",
    "            \n",
    "            # Check if this is a new best score (only if no DNN retrain happened)\n",
    "            elif candidate_score > best_ensemble_score:\n",
    "                model_type = metadata.get('classifier_type', 'unknown')\n",
    "                logger.info(f'NEW BEST: {candidate_score:.6f} (Î”=+{candidate_score - best_ensemble_score:.6f}) | Model: {model_type}')\n",
    "                best_ensemble_score = candidate_score\n",
    "                iterations_since_improvement = 0\n",
    "            else:\n",
    "                # Model accepted but didn't improve best score\n",
    "                best_ensemble_score = candidate_score\n",
    "                iterations_since_improvement += 1\n",
    "        else:\n",
    "            iterations_since_improvement += 1\n",
    "        \n",
    "        # Update temperature\n",
    "        temperature = update_temperature(\n",
    "            iteration=current_iter,\n",
    "            acceptance_history=[accept],\n",
    "            current_temperature=temperature,\n",
    "            base_temperature=BASE_TEMPERATURE,\n",
    "            decay_rate=TEMPERATURE_DECAY\n",
    "        )\n",
    "    \n",
    "    # Log batch summary\n",
    "    timeouts = sum(1 for r in results if r.get('timeout', False))\n",
    "    logger.info(f'BATCH {batch_counter} COMPLETE: {accepted_count}/{len(results)} accepted, {timeouts} timeouts | Ensemble: {len(ensemble_models)}, Best: {best_ensemble_score:.4f}')\n",
    "    \n",
    "    # Increment batch counter\n",
    "    batch_counter += 1\n",
    "    \n",
    "    # Move to next batch\n",
    "    iteration += len(batch_tasks)\n",
    "    \n",
    "    # Check termination\n",
    "    if iterations_since_improvement >= PLATEAU_ITERATIONS:\n",
    "        logger.info(f'TERMINATING: No improvement for {PLATEAU_ITERATIONS} iterations')\n",
    "        print(f'TERMINATING: No improvement for {PLATEAU_ITERATIONS} iterations')\n",
    "        break\n",
    "\n",
    "# Calculate final acceptance rate and timeout rate\n",
    "conn = ensemble_database.sqlite3.connect(ensemble_database.DB_PATH)\n",
    "acceptance_stats = conn.execute('SELECT COUNT(*) as total, SUM(accepted) as accepted FROM ensemble_log WHERE iteration_num > 0').fetchone()\n",
    "timeout_stats = conn.execute('SELECT SUM(timeout) as timeouts FROM ensemble_log WHERE iteration_num > 0').fetchone()\n",
    "conn.close()\n",
    "\n",
    "acceptance_rate = acceptance_stats[1] / acceptance_stats[0] if acceptance_stats[0] > 0 else 0.0\n",
    "timeout_rate = timeout_stats[0] / acceptance_stats[0] if acceptance_stats[0] > 0 else 0.0\n",
    "logger.info('TRAINING COMPLETE')\n",
    "logger.info('TRAINING COMPLETE')logger.info('TRAINING COMPLETE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e4cad",
   "metadata": {},
   "source": [
    "## Save final checkpoint and bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f505a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final checkpoint\n",
    "save_checkpoint(\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    ensemble_models=ensemble_models,\n",
    "    stage2_model=stage2_model,\n",
    "    iteration=iteration - 1,\n",
    "    temperature=temperature,\n",
    "    best_score=best_ensemble_score,\n",
    "    acceptance_history=[],\n",
    "    metadata={\n",
    "        'total_iterations': iteration,\n",
    "        'final_ensemble_size': len(ensemble_models),\n",
    "        'acceptance_rate': acceptance_rate,\n",
    "        'best_score': best_ensemble_score,\n",
    "        'parallel_batch_size': BATCH_SIZE,\n",
    "        'n_workers': N_WORKERS\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = MODELS_DIR / 'ensemble_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'ensemble_size': len(ensemble_models),\n",
    "        'total_iterations': iteration,\n",
    "        'best_score': best_ensemble_score,\n",
    "        'acceptance_rate': acceptance_rate,\n",
    "        'training_completed': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'parallel_batch_size': BATCH_SIZE,\n",
    "        'n_workers': N_WORKERS\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nCheckpoint saved: {CHECKPOINT_PATH}\")\n",
    "print(f\"Metadata saved: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final ensemble bundle for Kaggle\n",
    "ensemble_bundle_path = MODELS_DIR / 'ensemble_bundle.joblib'\n",
    "\n",
    "ensemble_bundle = {\n",
    "    'ensemble_models': ensemble_models,\n",
    "    'stage2_model': stage2_model,\n",
    "    'metadata': {\n",
    "        'ensemble_size': len(ensemble_models),\n",
    "        'total_iterations': iteration,\n",
    "        'best_score': best_ensemble_score,\n",
    "        'acceptance_rate': acceptance_rate,\n",
    "        'training_completed': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'parallel_batch_size': BATCH_SIZE,\n",
    "        'n_workers': N_WORKERS\n",
    "    },\n",
    "    'base_preprocessor': base_preprocessor,\n",
    "    'feature_info': {\n",
    "        'numerical_features': numerical_features,\n",
    "        'ordinal_features': ordinal_features,\n",
    "        'nominal_features': nominal_features,\n",
    "        'education_categories': education_categories,\n",
    "        'income_categories': income_categories\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(ensemble_bundle, ensemble_bundle_path, compress=3)\n",
    "\n",
    "print(f\"\\nFinal ensemble bundle saved: {ensemble_bundle_path}\")\n",
    "print(f\"File size: {ensemble_bundle_path.stat().st_size / (1024**2):.1f} MB\")\n",
    "print(f\"\\nTo load on Kaggle:\")\n",
    "print(f\"  ensemble_bundle = joblib.load('ensemble_bundle.joblib')\")\n",
    "print(f\"  ensemble_models = ensemble_bundle['ensemble_models']\")\n",
    "print(f\"  stage2_model = ensemble_bundle['stage2_model']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wrapper class\n",
    "sys.path.insert(0, str(MODELS_BASE_DIR))\n",
    "\n",
    "# Create wrapped model\n",
    "wrapped_model = EnsembleClassifier(\n",
    "    ensemble_models=ensemble_models,\n",
    "    stage2_model=stage2_model,\n",
    "    aggregation='mean'  # Fallback if stage2_model is None\n",
    ")\n",
    "\n",
    "# Save as single joblib file\n",
    "wrapped_model_path = MODELS_DIR / 'ensemble_model.joblib'\n",
    "joblib.dump(wrapped_model, wrapped_model_path, compress=3)\n",
    "\n",
    "print(f\"\\nWrapped ensemble model saved: {wrapped_model_path}\")\n",
    "print(f\"File size: {wrapped_model_path.stat().st_size / (1024**2):.1f} MB\")\n",
    "print(f\"\\nModel info: {wrapped_model}\")\n",
    "print(f\"\\nTo use on Kaggle:\")\n",
    "print(f\"  1. Upload to Kaggle dataset:\")\n",
    "print(f\"     - {wrapped_model_path.name}\")\n",
    "print(f\"     - {MODELS_BASE_DIR / 'ensemble_classifier.py'}\")\n",
    "print(f\"  2. In inference notebook:\")\n",
    "print(f\"     from ensemble_classifier import EnsembleClassifier\")\n",
    "print(f\"     model = joblib.load('ensemble_model.joblib')\")\n",
    "print(f\"     predictions = model.predict(test_df)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7f59f",
   "metadata": {},
   "source": [
    "## Create wrapped ensemble model for Kaggle\n",
    "\n",
    "Create a sklearn-compatible wrapper that bundles the entire ensemble into a single classifier.\n",
    "This makes inference identical to the logistic regression workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab336e9",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nFinal Statistics:\")\n",
    "print(f\"  Ensemble size: {len(ensemble_models)}\")\n",
    "print(f\"  Best validation AUC: {best_ensemble_score:.6f}\")\n",
    "print(f\"  Total iterations: {iteration}\")\n",
    "print(f\"  Acceptance rate: {acceptance_rate:.1%}\")\n",
    "print(f\"  Parallel configuration: {BATCH_SIZE} candidates, {N_WORKERS} workers\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  Database: {ensemble_database.DB_PATH}\")\n",
    "print(f\"  Models: {ENSEMBLE_DIR}\")\n",
    "print(f\"  Checkpoint: {CHECKPOINT_PATH}\")\n",
    "print(f\"  Metadata: {metadata_path}\")\n",
    "print(f\"  Bundle: {ensemble_bundle_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
