{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e07897",
   "metadata": {},
   "source": [
    "## Setup and configuration\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b77f679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 02:32:40.204420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765179160.228091 1192274 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765179160.235381 1192274 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Available CPUs: 24\n",
      "GPUs available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# GPU Configuration - Use P100 (GPU 1) for Stage 2 DNN training\n",
    "# Set library path for CUDA libraries installed via pip\n",
    "venv_cuda_libs = '/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/nvidia/cudnn/lib'\n",
    "\n",
    "if 'LD_LIBRARY_PATH' in os.environ:\n",
    "    os.environ['LD_LIBRARY_PATH'] = f\"{os.environ['LD_LIBRARY_PATH']}:{venv_cuda_libs}\"\n",
    "\n",
    "else:\n",
    "    os.environ['LD_LIBRARY_PATH'] = venv_cuda_libs\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'  # 0=GTX1080, 1=P100\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Third party imports\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add models directory to path for ensemble_classifier import\n",
    "sys.path.insert(0, str(Path('../models').resolve()))\n",
    "\n",
    "# Import ensemble modules\n",
    "from ensemble_classifier import EnsembleClassifier\n",
    "from functions import ensemble_database\n",
    "from functions.ensemble_initialization import create_data_splits, create_base_preprocessor, train_founder_model\n",
    "from functions.ensemble_parallel import train_single_candidate, prepare_training_batch\n",
    "from functions.ensemble_evaluation import evaluate_candidate_ensemble\n",
    "from functions.ensemble_stage2_training import train_or_expand_stage2_model, save_ensemble_bundle\n",
    "from functions.ensemble_hill_climbing import (\n",
    "    adaptive_simulated_annealing_acceptance,\n",
    "    update_temperature,\n",
    "    log_iteration\n",
    ")\n",
    "from functions.ensemble_stage2_model import save_checkpoint\n",
    "\n",
    "# Configure TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Detect available CPUs\n",
    "n_cpus = cpu_count()\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Available CPUs: {n_cpus}\")\n",
    "\n",
    "# Check GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPUs available: {gpus}\")\n",
    "print(f\"Number of GPUs: {len(gpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77467d",
   "metadata": {},
   "source": [
    "### Ensemble training & hill climb parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88b2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration:\n",
      "  Total CPUs available: 20\n",
      "  Parallel workers: 20\n",
      "  Batch size: 20\n",
      "  Model timeout: 120 minutes\n"
     ]
    }
   ],
   "source": [
    "# Random state for reproducibility\n",
    "RANDOM_STATE = 315\n",
    "\n",
    "# CPU allocation for parallel training\n",
    "# Set to None to use all available CPUs, or specify a number to limit\n",
    "N_CPUS = 20\n",
    "\n",
    "if N_CPUS is None:\n",
    "    import multiprocessing\n",
    "    N_CPUS = multiprocessing.cpu_count()\n",
    "\n",
    "# Parallel training configuration\n",
    "BATCH_SIZE = 20                  # Train this many candidates in parallel\n",
    "N_WORKERS = N_CPUS               # Use all available CPUs as workers\n",
    "MODEL_TIMEOUT_MINUTES = 2 * 60   # Maximum training time per model (minutes)\n",
    "\n",
    "# Hill climbing configuration\n",
    "MAX_ITERATIONS = 1000\n",
    "PLATEAU_ITERATIONS = 100\n",
    "BASE_TEMPERATURE = 0.05\n",
    "TEMPERATURE_DECAY = 0.998\n",
    "\n",
    "# Stage 2 DNN configuration\n",
    "STAGE2_BATCH_SIZE_MODELS = 20  # Retrain DNN every N accepted models\n",
    "STAGE2_EPOCHS = 100\n",
    "STAGE2_BATCH_SIZE = 128\n",
    "STAGE2_PATIENCE = 10\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data')\n",
    "MODELS_BASE_DIR = Path('../models')\n",
    "LOGS_DIR = Path('../logs')\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "MODELS_DIR = MODELS_BASE_DIR / f'run_{timestamp}'\n",
    "ENSEMBLE_DIR = MODELS_DIR / 'ensemble_stage1_models'\n",
    "CHECKPOINT_PATH = MODELS_DIR / 'ensemble_checkpoint.pkl'\n",
    "LOG_FILE = LOGS_DIR / f'training_{timestamp}.log'\n",
    "\n",
    "# Create directories\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ENSEMBLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Total CPUs available: {N_CPUS}\")\n",
    "print(f\"  Parallel workers: {N_WORKERS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Model timeout: {MODEL_TIMEOUT_MINUTES} minutes\")\n",
    "print(f\"  Log file: {LOG_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8897d92",
   "metadata": {},
   "source": [
    "### Initialize progress dashboard database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c236bbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing database: /mnt/arkk/kaggle/diabetes-prediction/data/ensemble_training.db\n",
      "Database initialized at: /mnt/arkk/kaggle/diabetes-prediction/data/ensemble_training.db\n"
     ]
    }
   ],
   "source": [
    "ensemble_database.reset_database()\n",
    "ensemble_database.init_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d732b6",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246e5d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (700000, 26)\n",
      "\n",
      "Class distribution:\n",
      "diagnosed_diabetes\n",
      "1.0    0.623296\n",
      "0.0    0.376704\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_df_path = 'https://gperdrizet.github.io/FSA_devops/assets/data/unit3/diabetes_prediction_train.csv'\n",
    "train_df = pd.read_csv(train_df_path)\n",
    "train_df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f'Training data shape: {train_df.shape}\\n')\n",
    "print('Class distribution:')\n",
    "print(train_df['diagnosed_diabetes'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff019cac",
   "metadata": {},
   "source": [
    "### Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f0af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'diagnosed_diabetes'\n",
    "\n",
    "numerical_features = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi',\n",
    "    'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate',\n",
    "    'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides',\n",
    "    'family_history_diabetes', 'hypertension_history', 'cardiovascular_history'\n",
    "]\n",
    "\n",
    "ordinal_features = ['education_level', 'income_level']\n",
    "education_categories = [['No formal', 'Highschool', 'Graduate', 'Postgraduate']]\n",
    "income_categories = [['Low', 'Lower-Middle', 'Middle', 'Upper-Middle', 'High']]\n",
    "nominal_features = ['gender', 'ethnicity', 'smoking_status', 'employment_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0e51f",
   "metadata": {},
   "source": [
    "### Trainining-validation-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c44282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info before batch preparation:\n",
      "  X_train_pool: <class 'pandas.core.frame.DataFrame'> - (420000, 25)\n",
      "  X_val_s1: <class 'pandas.core.frame.DataFrame'> - (140000, 25)\n",
      "  X_val_s2: <class 'pandas.core.series.Series'> - (140000,)\n"
     ]
    }
   ],
   "source": [
    "# Create fixed three-way data split\n",
    "X_train_pool, X_val_s1, X_val_s2, y_train_pool, y_val_s1, y_val_s2 = create_data_splits(\n",
    "    train_df, label, RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Data info before batch preparation:\")\n",
    "print(f\"  X_train_pool: {type(X_train_pool)} - {X_train_pool.shape if hasattr(X_train_pool, 'shape') else 'N/A'}\")\n",
    "print(f\"  X_val_s1: {type(X_val_s1)} - {X_val_s1.shape if hasattr(X_val_s1, 'shape') else 'N/A'}\")\n",
    "print(f\"  X_val_s2: {type(y_val_s2)} - {y_val_s2.shape if hasattr(y_val_s2, 'shape') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7eda43",
   "metadata": {},
   "source": [
    "### Base data preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230c09f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base preprocessor created\n",
      "  Numerical features: 18\n",
      "  Ordinal features: 2\n",
      "  Nominal features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;alcohol_consumption_per_week&#x27;,\n",
       "                                  &#x27;physical_activity_minutes_per_week&#x27;,\n",
       "                                  &#x27;diet_score&#x27;, &#x27;sleep_hours_per_day&#x27;,\n",
       "                                  &#x27;screen_time_hours_per_day&#x27;, &#x27;bmi&#x27;,\n",
       "                                  &#x27;waist_to_hip_ratio&#x27;, &#x27;systolic_bp&#x27;,\n",
       "                                  &#x27;diastolic_bp&#x27;, &#x27;heart_rate&#x27;,\n",
       "                                  &#x27;cholesterol_total&#x27;, &#x27;hdl_cholesterol&#x27;,\n",
       "                                  &#x27;ldl_cholesterol&#x27;, &#x27;t...\n",
       "                                 OrdinalEncoder(categories=[[&#x27;No formal&#x27;,\n",
       "                                                             &#x27;Highschool&#x27;,\n",
       "                                                             &#x27;Graduate&#x27;,\n",
       "                                                             &#x27;Postgraduate&#x27;],\n",
       "                                                            [&#x27;Low&#x27;,\n",
       "                                                             &#x27;Lower-Middle&#x27;,\n",
       "                                                             &#x27;Middle&#x27;,\n",
       "                                                             &#x27;Upper-Middle&#x27;,\n",
       "                                                             &#x27;High&#x27;]],\n",
       "                                                handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                unknown_value=-1),\n",
       "                                 [&#x27;education_level&#x27;, &#x27;income_level&#x27;]),\n",
       "                                (&#x27;nom&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;gender&#x27;, &#x27;ethnicity&#x27;, &#x27;smoking_status&#x27;,\n",
       "                                  &#x27;employment_status&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;alcohol_consumption_per_week&#x27;,\n",
       "                                  &#x27;physical_activity_minutes_per_week&#x27;,\n",
       "                                  &#x27;diet_score&#x27;, &#x27;sleep_hours_per_day&#x27;,\n",
       "                                  &#x27;screen_time_hours_per_day&#x27;, &#x27;bmi&#x27;,\n",
       "                                  &#x27;waist_to_hip_ratio&#x27;, &#x27;systolic_bp&#x27;,\n",
       "                                  &#x27;diastolic_bp&#x27;, &#x27;heart_rate&#x27;,\n",
       "                                  &#x27;cholesterol_total&#x27;, &#x27;hdl_cholesterol&#x27;,\n",
       "                                  &#x27;ldl_cholesterol&#x27;, &#x27;t...\n",
       "                                 OrdinalEncoder(categories=[[&#x27;No formal&#x27;,\n",
       "                                                             &#x27;Highschool&#x27;,\n",
       "                                                             &#x27;Graduate&#x27;,\n",
       "                                                             &#x27;Postgraduate&#x27;],\n",
       "                                                            [&#x27;Low&#x27;,\n",
       "                                                             &#x27;Lower-Middle&#x27;,\n",
       "                                                             &#x27;Middle&#x27;,\n",
       "                                                             &#x27;Upper-Middle&#x27;,\n",
       "                                                             &#x27;High&#x27;]],\n",
       "                                                handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                unknown_value=-1),\n",
       "                                 [&#x27;education_level&#x27;, &#x27;income_level&#x27;]),\n",
       "                                (&#x27;nom&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;gender&#x27;, &#x27;ethnicity&#x27;, &#x27;smoking_status&#x27;,\n",
       "                                  &#x27;employment_status&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">num</label><div class=\"sk-toggleable__content \"><pre>[&#x27;age&#x27;, &#x27;alcohol_consumption_per_week&#x27;, &#x27;physical_activity_minutes_per_week&#x27;, &#x27;diet_score&#x27;, &#x27;sleep_hours_per_day&#x27;, &#x27;screen_time_hours_per_day&#x27;, &#x27;bmi&#x27;, &#x27;waist_to_hip_ratio&#x27;, &#x27;systolic_bp&#x27;, &#x27;diastolic_bp&#x27;, &#x27;heart_rate&#x27;, &#x27;cholesterol_total&#x27;, &#x27;hdl_cholesterol&#x27;, &#x27;ldl_cholesterol&#x27;, &#x27;triglycerides&#x27;, &#x27;family_history_diabetes&#x27;, &#x27;hypertension_history&#x27;, &#x27;cardiovascular_history&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">ord</label><div class=\"sk-toggleable__content \"><pre>[&#x27;education_level&#x27;, &#x27;income_level&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OrdinalEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OrdinalEncoder(categories=[[&#x27;No formal&#x27;, &#x27;Highschool&#x27;, &#x27;Graduate&#x27;,\n",
       "                            &#x27;Postgraduate&#x27;],\n",
       "                           [&#x27;Low&#x27;, &#x27;Lower-Middle&#x27;, &#x27;Middle&#x27;, &#x27;Upper-Middle&#x27;,\n",
       "                            &#x27;High&#x27;]],\n",
       "               handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">nom</label><div class=\"sk-toggleable__content \"><pre>[&#x27;gender&#x27;, &#x27;ethnicity&#x27;, &#x27;smoking_status&#x27;, &#x27;employment_status&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('scaler', StandardScaler())]),\n",
       "                                 ['age', 'alcohol_consumption_per_week',\n",
       "                                  'physical_activity_minutes_per_week',\n",
       "                                  'diet_score', 'sleep_hours_per_day',\n",
       "                                  'screen_time_hours_per_day', 'bmi',\n",
       "                                  'waist_to_hip_ratio', 'systolic_bp',\n",
       "                                  'diastolic_bp', 'heart_rate',\n",
       "                                  'cholesterol_total', 'hdl_cholesterol',\n",
       "                                  'ldl_cholesterol', 't...\n",
       "                                 OrdinalEncoder(categories=[['No formal',\n",
       "                                                             'Highschool',\n",
       "                                                             'Graduate',\n",
       "                                                             'Postgraduate'],\n",
       "                                                            ['Low',\n",
       "                                                             'Lower-Middle',\n",
       "                                                             'Middle',\n",
       "                                                             'Upper-Middle',\n",
       "                                                             'High']],\n",
       "                                                handle_unknown='use_encoded_value',\n",
       "                                                unknown_value=-1),\n",
       "                                 ['education_level', 'income_level']),\n",
       "                                ('nom',\n",
       "                                 OneHotEncoder(drop='first',\n",
       "                                               handle_unknown='ignore',\n",
       "                                               sparse_output=False),\n",
       "                                 ['gender', 'ethnicity', 'smoking_status',\n",
       "                                  'employment_status'])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create base preprocessor\n",
    "base_preprocessor = create_base_preprocessor(\n",
    "    numerical_features, ordinal_features, nominal_features,\n",
    "    education_categories, income_categories\n",
    ")\n",
    "\n",
    "base_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd576f7",
   "metadata": {},
   "source": [
    "## Initialize ensemble with founder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73218e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING FOUNDER MODEL (baseline only - NOT added to ensemble)\n",
      "================================================================================\n",
      "\n",
      "Training founder model\n",
      "--------------------------------------------------------------------------------\n",
      "  Training samples: 42,000 (10% of 420,000 pool)\n",
      "  Pipeline config:\n",
      "    Classifier: naive_bayes\n",
      "    Transformers: []\n",
      "    Dimensionality reduction: fast_ica\n",
      "  Training pipeline...\n",
      "\n",
      "Training founder model\n",
      "--------------------------------------------------------------------------------\n",
      "  Training samples: 42,000 (10% of 420,000 pool)\n",
      "  Pipeline config:\n",
      "    Classifier: naive_bayes\n",
      "    Transformers: []\n",
      "    Dimensionality reduction: fast_ica\n",
      "  Training pipeline...\n",
      "  Training complete (227.9s)\n",
      "  Training complete (227.9s)\n",
      "  Stage 1 validation AUC: 0.578409\n",
      "  Stage 2 validation AUC: 0.580149\n",
      "\n",
      "================================================================================\n",
      "FOUNDER MODEL COMPLETE - Baseline score established\n",
      "================================================================================\n",
      "\n",
      "Founder baseline AUC: 0.580149\n",
      "Ensemble starts empty - first batch will be iterations 1-20\n",
      "Stage 2 DNN will be trained after 20 accepted models\n",
      "  Stage 1 validation AUC: 0.578409\n",
      "  Stage 2 validation AUC: 0.580149\n",
      "\n",
      "================================================================================\n",
      "FOUNDER MODEL COMPLETE - Baseline score established\n",
      "================================================================================\n",
      "\n",
      "Founder baseline AUC: 0.580149\n",
      "Ensemble starts empty - first batch will be iterations 1-20\n",
      "Stage 2 DNN will be trained after 20 accepted models\n"
     ]
    }
   ],
   "source": [
    "# Train founder model (baseline only - NOT added to ensemble)\n",
    "founder_auc = train_founder_model(\n",
    "    X_train_pool, X_val_s1, X_val_s2, y_train_pool, y_val_s1, y_val_s2,\n",
    "    base_preprocessor, RANDOM_STATE, BASE_TEMPERATURE, ENSEMBLE_DIR\n",
    ")\n",
    "\n",
    "# Initialize ensemble (EMPTY - founder not included)\n",
    "ensemble_models = []\n",
    "stage2_model = None\n",
    "best_ensemble_score = founder_auc\n",
    "\n",
    "# Initialize hill climbing variables (start at iteration 1, not 0)\n",
    "start_iteration = 1\n",
    "temperature = BASE_TEMPERATURE\n",
    "\n",
    "print(f\"\\nFounder baseline AUC: {founder_auc:.6f}\")\n",
    "print(f\"Ensemble starts empty - first batch will be iterations 1-{BATCH_SIZE}\")\n",
    "print(f\"Stage 2 DNN will be trained after {STAGE2_BATCH_SIZE_MODELS} accepted models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8df88a",
   "metadata": {},
   "source": [
    "## Parallel hill climbing loop\n",
    "\n",
    "Iteratively trains batches of candidate models in parallel, evaluates with hybrid scoring,\n",
    "and accepts/rejects using simulated annealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1074db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH Starting at iteration 1\n",
      "Ensemble size: 0 | Best score: 0.580149 | Temperature: 0.050000 | No improvement: 0/100\n",
      "\n",
      "Training 20 candidates in parallel (120 min timeout per model)...\n",
      "\n",
      "Training 20 candidates in parallel (120 min timeout per model)...\n",
      "  [1/20] Iteration 1: ridge AUC=0.603326 (3.0s)\n",
      "  [1/20] Iteration 1: ridge AUC=0.603326 (3.0s)\n",
      "  [2/20] Iteration 3: logistic AUC=0.652528 (2.6s)\n",
      "  [2/20] Iteration 3: logistic AUC=0.652528 (2.6s)\n",
      "  [3/20] Iteration 2 FAILED: n_components(12) must be <= n_features(7).\n",
      "  [3/20] Iteration 2 FAILED: n_components(12) must be <= n_features(7).\n",
      "  [4/20] Iteration 9: ridge AUC=0.585364 (2.2s)\n",
      "  [4/20] Iteration 9: ridge AUC=0.585364 (2.2s)\n",
      "  [5/20] Iteration 15: lda AUC=0.526176 (3.3s)\n",
      "  [5/20] Iteration 15: lda AUC=0.526176 (3.3s)\n",
      "  [6/20] Iteration 14: lasso AUC=0.656725 (5.3s)\n",
      "  [6/20] Iteration 14: lasso AUC=0.656725 (5.3s)\n",
      "  [7/20] Iteration 17: lda AUC=0.607280 (4.1s)\n",
      "  [7/20] Iteration 17: lda AUC=0.607280 (4.1s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [8/20] Iteration 16: random_forest AUC=0.615958 (13.5s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [9/20] Iteration 11: linear_svc AUC=0.498639 (32.5s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [10/20] Iteration 18: linear_svc AUC=0.655322 (41.3s)\n",
      "  [11/20] Iteration 12: mlp AUC=0.637592 (137.2s)\n",
      "  [11/20] Iteration 12: mlp AUC=0.637592 (137.2s)\n",
      "  [12/20] Iteration 10: ridge AUC=0.553904 (156.2s)\n",
      "  [12/20] Iteration 10: ridge AUC=0.553904 (156.2s)\n",
      "  [13/20] Iteration 4 TIMEOUT: random_forest exceeded 120 minutes\n",
      "  [13/20] Iteration 4 TIMEOUT: random_forest exceeded 120 minutes\n",
      "  [14/20] Iteration 5 TIMEOUT: linear_svc exceeded 120 minutes\n",
      "  [14/20] Iteration 5 TIMEOUT: linear_svc exceeded 120 minutes\n",
      "  [15/20] Iteration 6 TIMEOUT: extra_trees exceeded 120 minutes\n",
      "  [16/20] Iteration 7 TIMEOUT: logistic exceeded 120 minutes\n",
      "  [15/20] Iteration 6 TIMEOUT: extra_trees exceeded 120 minutes\n",
      "  [16/20] Iteration 7 TIMEOUT: logistic exceeded 120 minutes\n",
      "  [17/20] Iteration 8 TIMEOUT: mlp exceeded 120 minutes\n",
      "  [17/20] Iteration 8 TIMEOUT: mlp exceeded 120 minutes\n",
      "  [18/20] Iteration 13 TIMEOUT: extra_trees exceeded 120 minutes\n",
      "  [18/20] Iteration 13 TIMEOUT: extra_trees exceeded 120 minutes\n",
      "  [19/20] Iteration 19 TIMEOUT: linear_svc exceeded 120 minutes\n",
      "  [19/20] Iteration 19 TIMEOUT: linear_svc exceeded 120 minutes\n",
      "  [20/20] Iteration 20 TIMEOUT: qda exceeded 120 minutes\n",
      "\n",
      "9/20 models failed during training\n",
      "  [20/20] Iteration 20 TIMEOUT: qda exceeded 120 minutes\n",
      "\n",
      "9/20 models failed during training\n",
      "\n",
      "Batch complete (7214.5s, 655.9s per model)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1: ridge | Stage 1 AUC: 0.603326\n",
      "  Ensemble AUC (single_model): 0.603326 (first model)\n",
      "  Decision: ACCEPT (improvement: Δ=0.023178)\n",
      "  New best score: 0.603326 (Δ=0.023178)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3: logistic | Stage 1 AUC: 0.652528\n",
      "\n",
      "Batch complete (7214.5s, 655.9s per model)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 1: ridge | Stage 1 AUC: 0.603326\n",
      "  Ensemble AUC (single_model): 0.603326 (first model)\n",
      "  Decision: ACCEPT (improvement: Δ=0.023178)\n",
      "  New best score: 0.603326 (Δ=0.023178)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3: logistic | Stage 1 AUC: 0.652528\n",
      "  Ensemble AUC (simple mean (all)): 0.684861 | Diversity: 0.111218\n",
      "  Decision: ACCEPT (improvement: Δ=0.081535)\n",
      "  New best score: 0.684861 (Δ=0.081535)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9: ridge | Stage 1 AUC: 0.585364\n",
      "  Ensemble AUC (simple mean (all)): 0.684861 | Diversity: 0.111218\n",
      "  Decision: ACCEPT (improvement: Δ=0.081535)\n",
      "  New best score: 0.684861 (Δ=0.081535)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9: ridge | Stage 1 AUC: 0.585364\n",
      "  Ensemble AUC (simple mean (all)): 0.685902 | Diversity: 0.193885\n",
      "  Decision: ACCEPT (improvement: Δ=0.001041)\n",
      "  New best score: 0.685902 (Δ=0.001041)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10: ridge | Stage 1 AUC: 0.553904\n",
      "  Ensemble AUC (simple mean (all)): 0.685902 | Diversity: 0.193885\n",
      "  Decision: ACCEPT (improvement: Δ=0.001041)\n",
      "  New best score: 0.685902 (Δ=0.001041)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10: ridge | Stage 1 AUC: 0.553904\n",
      "  Ensemble AUC (simple mean (all)): 0.685386 | Diversity: 0.193886\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.000516, div=0.194, bonus=0.015306)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11: linear_svc | Stage 1 AUC: 0.498639\n",
      "  Ensemble AUC (simple mean (all)): 0.685386 | Diversity: 0.193886\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.000516, div=0.194, bonus=0.015306)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11: linear_svc | Stage 1 AUC: 0.498639\n",
      "  Ensemble AUC (simple mean (all)): 0.685371 | Diversity: 0.122951\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.000531, div=0.123, bonus=0.018852)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12: mlp | Stage 1 AUC: 0.637592\n",
      "  Ensemble AUC (simple mean (all)): 0.685371 | Diversity: 0.122951\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.000531, div=0.123, bonus=0.018852)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12: mlp | Stage 1 AUC: 0.637592\n",
      "  Ensemble AUC (simple mean (all)): 0.681836 | Diversity: 0.194495\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.004066, div=0.194, bonus=0.015275)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14: lasso | Stage 1 AUC: 0.656725\n",
      "  Ensemble AUC (simple mean (all)): 0.681836 | Diversity: 0.194495\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.004066, div=0.194, bonus=0.015275)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14: lasso | Stage 1 AUC: 0.656725\n",
      "  Ensemble AUC (simple mean (all)): 0.680829 | Diversity: 0.271417\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.005073, div=0.271, bonus=0.011429)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15: lda | Stage 1 AUC: 0.526176\n",
      "  Ensemble AUC (simple mean (all)): 0.680829 | Diversity: 0.271417\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.005073, div=0.271, bonus=0.011429)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15: lda | Stage 1 AUC: 0.526176\n",
      "  Ensemble AUC (simple mean (all)): 0.680817 | Diversity: 0.205107\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.005085, div=0.205, bonus=0.014745)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16: random_forest | Stage 1 AUC: 0.615958\n",
      "  Ensemble AUC (simple mean (all)): 0.680817 | Diversity: 0.205107\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.005085, div=0.205, bonus=0.014745)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16: random_forest | Stage 1 AUC: 0.615958\n",
      "  Ensemble AUC (simple mean (all)): 0.679653 | Diversity: 0.248035\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.006248, div=0.248, bonus=0.012598)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17: lda | Stage 1 AUC: 0.607280\n",
      "  Ensemble AUC (simple mean (all)): 0.679653 | Diversity: 0.248035\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.006248, div=0.248, bonus=0.012598)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17: lda | Stage 1 AUC: 0.607280\n",
      "  Ensemble AUC (simple mean (all)): 0.679121 | Diversity: 0.253780\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.006780, div=0.254, bonus=0.012311)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18: linear_svc | Stage 1 AUC: 0.655322\n",
      "  Ensemble AUC (simple mean (all)): 0.679121 | Diversity: 0.253780\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.006780, div=0.254, bonus=0.012311)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18: linear_svc | Stage 1 AUC: 0.655322\n",
      "  Ensemble AUC (simple mean (all)): 0.678075 | Diversity: 0.296798\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.007827, div=0.297, bonus=0.010160)\n",
      "BATCH Starting at iteration 12\n",
      "Ensemble size: 11 | Best score: 0.685902 | Temperature: 0.048230 | No improvement: 8/100\n",
      "  Ensemble AUC (simple mean (all)): 0.678075 | Diversity: 0.296798\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.007827, div=0.297, bonus=0.010160)\n",
      "BATCH Starting at iteration 12\n",
      "Ensemble size: 11 | Best score: 0.685902 | Temperature: 0.048230 | No improvement: 8/100\n",
      "\n",
      "Training 20 candidates in parallel (120 min timeout per model)...\n",
      "\n",
      "Training 20 candidates in parallel (120 min timeout per model)...\n",
      "  [1/20] Iteration 14: lasso AUC=0.592871 (2.2s)\n",
      "  [2/20] Iteration 15: lda AUC=0.550168 (1.9s)\n",
      "  [1/20] Iteration 14: lasso AUC=0.592871 (2.2s)\n",
      "  [2/20] Iteration 15: lda AUC=0.550168 (1.9s)\n",
      "  [3/20] Iteration 17: lda AUC=0.642150 (2.4s)\n",
      "  [3/20] Iteration 17: lda AUC=0.642150 (2.4s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/naive_bayes.py:1199: RuntimeWarning: invalid value encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [4/20] Iteration 21 FAILED: Input contains NaN.\n",
      "  [5/20] Iteration 23: ridge AUC=0.613431 (4.0s)\n",
      "  [5/20] Iteration 23: ridge AUC=0.613431 (4.0s)\n",
      "  [6/20] Iteration 22: ridge AUC=0.561016 (4.8s)\n",
      "  [6/20] Iteration 22: ridge AUC=0.561016 (4.8s)\n",
      "  [7/20] Iteration 16: random_forest AUC=0.656650 (13.3s)\n",
      "  [7/20] Iteration 16: random_forest AUC=0.656650 (13.3s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [8/20] Iteration 31: gradient_boosting AUC=0.655331 (31.5s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [9/20] Iteration 25: linear_svc AUC=0.646944 (43.2s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [10/20] Iteration 18: linear_svc AUC=0.686301 (52.0s)\n",
      "  [11/20] Iteration 12: mlp AUC=0.505658 (106.0s)\n",
      "  [11/20] Iteration 12: mlp AUC=0.505658 (106.0s)\n",
      "  [12/20] Iteration 27: naive_bayes AUC=0.592721 (244.2s)\n",
      "  [12/20] Iteration 27: naive_bayes AUC=0.592721 (244.2s)\n",
      "  [13/20] Iteration 13 TIMEOUT: extra_trees exceeded 120 minutes\n",
      "  [13/20] Iteration 13 TIMEOUT: extra_trees exceeded 120 minutes\n",
      "  [14/20] Iteration 19 TIMEOUT: linear_svc exceeded 120 minutes\n",
      "  [14/20] Iteration 19 TIMEOUT: linear_svc exceeded 120 minutes\n",
      "  [15/20] Iteration 20 TIMEOUT: qda exceeded 120 minutes\n",
      "  [15/20] Iteration 20 TIMEOUT: qda exceeded 120 minutes\n",
      "  [16/20] Iteration 24 TIMEOUT: qda exceeded 120 minutes\n",
      "  [16/20] Iteration 24 TIMEOUT: qda exceeded 120 minutes\n",
      "  [17/20] Iteration 26 TIMEOUT: sgd_classifier exceeded 120 minutes\n",
      "  [17/20] Iteration 26 TIMEOUT: sgd_classifier exceeded 120 minutes\n",
      "  [18/20] Iteration 28 TIMEOUT: random_forest exceeded 120 minutes\n",
      "  [18/20] Iteration 28 TIMEOUT: random_forest exceeded 120 minutes\n",
      "  [19/20] Iteration 29 TIMEOUT: naive_bayes exceeded 120 minutes\n",
      "  [19/20] Iteration 29 TIMEOUT: naive_bayes exceeded 120 minutes\n",
      "  [20/20] Iteration 30 TIMEOUT: mlp exceeded 120 minutes\n",
      "\n",
      "9/20 models failed during training\n",
      "  [20/20] Iteration 30 TIMEOUT: mlp exceeded 120 minutes\n",
      "\n",
      "9/20 models failed during training\n",
      "\n",
      "Batch complete (7212.8s, 655.7s per model)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12: mlp | Stage 1 AUC: 0.505658\n",
      "\n",
      "Batch complete (7212.8s, 655.7s per model)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12: mlp | Stage 1 AUC: 0.505658\n",
      "  Ensemble AUC (simple mean (all)): 0.677995 | Diversity: 0.249878\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.007907, div=0.250, bonus=0.012506)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14: lasso | Stage 1 AUC: 0.592871\n",
      "  Ensemble AUC (simple mean (all)): 0.677995 | Diversity: 0.249878\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.007907, div=0.250, bonus=0.012506)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14: lasso | Stage 1 AUC: 0.592871\n",
      "  Ensemble AUC (simple mean (all)): 0.675850 | Diversity: 0.261641\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.010052, div=0.262, bonus=0.011918)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15: lda | Stage 1 AUC: 0.550168\n",
      "  Ensemble AUC (simple mean (all)): 0.675850 | Diversity: 0.261641\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.010052, div=0.262, bonus=0.011918)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15: lda | Stage 1 AUC: 0.550168\n",
      "  Ensemble AUC (simple mean (all)): 0.675837 | Diversity: 0.227718\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.010065, div=0.228, bonus=0.013614)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16: random_forest | Stage 1 AUC: 0.656650\n",
      "  Ensemble AUC (simple mean (all)): 0.675837 | Diversity: 0.227718\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.010065, div=0.228, bonus=0.013614)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16: random_forest | Stage 1 AUC: 0.656650\n",
      "  Ensemble AUC (simple mean (all)): 0.677849 | Diversity: 0.247329\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.008053, div=0.247, bonus=0.012634)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17: lda | Stage 1 AUC: 0.642150\n",
      "  Ensemble AUC (simple mean (all)): 0.677849 | Diversity: 0.247329\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.008053, div=0.247, bonus=0.012634)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17: lda | Stage 1 AUC: 0.642150\n",
      "  Ensemble AUC (simple mean (all)): 0.678842 | Diversity: 0.269971\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.007060, div=0.270, bonus=0.011501)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18: linear_svc | Stage 1 AUC: 0.686301\n",
      "  Ensemble AUC (simple mean (all)): 0.678842 | Diversity: 0.269971\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.007060, div=0.270, bonus=0.011501)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18: linear_svc | Stage 1 AUC: 0.686301\n",
      "  Ensemble AUC (simple mean (all)): 0.683167 | Diversity: 0.295309\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.002735, div=0.295, bonus=0.010235)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 22: ridge | Stage 1 AUC: 0.561016\n",
      "  Ensemble AUC (simple mean (all)): 0.683167 | Diversity: 0.295309\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.002735, div=0.295, bonus=0.010235)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 22: ridge | Stage 1 AUC: 0.561016\n",
      "  Ensemble AUC (simple mean (all)): 0.682635 | Diversity: 0.286085\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.003267, div=0.286, bonus=0.010696)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 23: ridge | Stage 1 AUC: 0.613431\n",
      "  Ensemble AUC (simple mean (all)): 0.682635 | Diversity: 0.286085\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.003267, div=0.286, bonus=0.010696)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 23: ridge | Stage 1 AUC: 0.613431\n",
      "  Ensemble AUC (simple mean (all)): 0.682399 | Diversity: 0.293031\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.003503, div=0.293, bonus=0.010348)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 25: linear_svc | Stage 1 AUC: 0.646944\n",
      "  Ensemble AUC (simple mean (all)): 0.682399 | Diversity: 0.293031\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.003503, div=0.293, bonus=0.010348)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 25: linear_svc | Stage 1 AUC: 0.646944\n",
      "  Ensemble AUC (simple mean (all)): 0.685498 | Diversity: 0.301474\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.000404, div=0.301, bonus=0.009926)\n",
      "\n",
      "================================================================================\n",
      "BATCH COMPLETE: Training stage 2 DNN on 20 models\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RUNNING STAGE 2 DNN HYPERPARAMETER OPTIMIZATION\n",
      "Ensemble size: 20 models\n",
      "================================================================================\n",
      "\n",
      "  Generating Stage 1 predictions...\n",
      "  Ensemble AUC (simple mean (all)): 0.685498 | Diversity: 0.301474\n",
      "  Decision: ACCEPT (diversity_bonus: Δ=-0.000404, div=0.301, bonus=0.009926)\n",
      "\n",
      "================================================================================\n",
      "BATCH COMPLETE: Training stage 2 DNN on 20 models\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RUNNING STAGE 2 DNN HYPERPARAMETER OPTIMIZATION\n",
      "Ensemble size: 20 models\n",
      "================================================================================\n",
      "\n",
      "  Generating Stage 1 predictions...\n",
      "  Training samples: 266,000 (X_val_s1 + 90% X_val_s2)\n",
      "  Validation samples: 14,000 (10% X_val_s2)\n",
      "  Running 40 trials with 3 executions each...\n",
      "  Training samples: 266,000 (X_val_s1 + 90% X_val_s2)\n",
      "  Validation samples: 14,000 (10% X_val_s2)\n",
      "  Running 40 trials with 3 executions each...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765194033.805006 1192274 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6856 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765194037.355113 1279233 service.cc:148] XLA service 0x7e946c00c560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1765194037.355142 1279233 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765194037.355113 1279233 service.cc:148] XLA service 0x7e946c00c560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1765194037.355142 1279233 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "I0000 00:00:1765194037.677465 1279233 cuda_dnn.cc:529] Loaded cuDNN version 91700\n",
      "I0000 00:00:1765194037.677465 1279233 cuda_dnn.cc:529] Loaded cuDNN version 91700\n",
      "I0000 00:00:1765194039.996372 1279233 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1765194039.996372 1279233 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 199\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# Check if we should train/retrain stage 2 DNN\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ensemble_models) % STAGE2_BATCH_SIZE_MODELS == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ensemble_models) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     stage2_model, final_score, stage2_memory_mb, stage2_time_sec = \u001b[43mtrain_or_expand_stage2_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensemble_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage2_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_s1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_s1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_s2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_s2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mSTAGE2_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTAGE2_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTAGE2_PATIENCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_iter\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;66;03m# Log DNN retrain score as separate entry\u001b[39;00m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  DNN Retrained: Final ensemble AUC = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/notebooks/functions/ensemble_stage2_training.py:238\u001b[39m, in \u001b[36mtrain_or_expand_stage2_model\u001b[39m\u001b[34m(ensemble_models, stage2_model, X_val_s1, y_val_s1, X_val_s2, y_val_s2, stage2_epochs, stage2_batch_size, stage2_patience, current_iter, optimize_every_n_batches, run_optimization, optimization_trials)\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEnsemble size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ensemble_models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m models\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    234\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    236\u001b[39m     optimize_and_update_config(\n\u001b[32m    237\u001b[39m         ensemble_models, X_val_s1, y_val_s1, X_val_s2, y_val_s2,\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m         max_trials=trials, executions_per_trial=executions\n\u001b[32m    239\u001b[39m     )\n\u001b[32m    241\u001b[39m \u001b[38;5;66;03m# Now print training header\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/notebooks/functions/ensemble_stage2_training.py:97\u001b[39m, in \u001b[36moptimize_and_update_config\u001b[39m\u001b[34m(ensemble_models, X_val_s1, y_val_s1, X_val_s2, y_val_s2, max_trials, executions_per_trial)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     95\u001b[39m tuner_dir = Path(\u001b[33m'\u001b[39m\u001b[33m../models/keras_tuner\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m best_model, best_hps = \u001b[43moptimize_stage2_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutions_per_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutions_per_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstage2_online_tuning_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mensemble_models\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtuner_dir\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Build optimized config dictionary\u001b[39;00m\n\u001b[32m    109\u001b[39m optimized_config = {\n\u001b[32m    110\u001b[39m     \u001b[33m'\u001b[39m\u001b[33marchitecture\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m    111\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mhidden_layers\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m   (...)\u001b[39m\u001b[32m    128\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mretrain_frequency\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m10\u001b[39m\n\u001b[32m    129\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/notebooks/functions/ensemble_stage2_model.py:277\u001b[39m, in \u001b[36moptimize_stage2_hyperparameters\u001b[39m\u001b[34m(X_train, y_train, X_val, y_val, max_trials, executions_per_trial, project_name, directory)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_end(trial)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[39m, in \u001b[36mBaseTuner._try_run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m         trial.status = trial_module.TrialStatus.COMPLETED\n\u001b[32m    276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[39m, in \u001b[36mBaseTuner._run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[32m    241\u001b[39m         \u001b[38;5;28mself\u001b[39m.oracle.objective.name\n\u001b[32m    242\u001b[39m     ):\n\u001b[32m    243\u001b[39m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[32m    244\u001b[39m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[32m    245\u001b[39m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[32m    246\u001b[39m         warnings.warn(\n\u001b[32m    247\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe use case of calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    254\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    255\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[39m, in \u001b[36mTuner.run_trial\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    312\u001b[39m     callbacks.append(model_checkpoint)\n\u001b[32m    313\u001b[39m     copied_kwargs[\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m] = callbacks\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     obj_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     histories.append(obj_value)\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[39m, in \u001b[36mTuner._build_and_fit_model\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m hp = trial.hyperparameters\n\u001b[32m    232\u001b[39m model = \u001b[38;5;28mself\u001b[39m._try_build(hp)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.config.multi_backend():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[39m, in \u001b[36mHyperModel.fit\u001b[39m\u001b[34m(self, hp, model, *args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, *args, **kwargs):\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/arkk/kaggle/diabetes-prediction/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:242\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) != expected_len:\n\u001b[32m    235\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    236\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSignature specifies \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m arguments, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Expected inputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.cached_definition.signature.input_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    238\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Received inputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Function Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.function_type\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mInterpolateRuntimeError\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m    243\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.control_dependencies(\u001b[38;5;28mself\u001b[39m._call_options.control_captures):\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# The caller must use record_operation to record this operation in the\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# eager case, so we enforce the same requirement for the non-eager\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;66;03m# case by explicitly pausing recording. We don't have a gradient\u001b[39;00m\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# registered for PartitionedCall, so recording this operation confuses\u001b[39;00m\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# forwardprop code (GradientTape manages to ignore it).\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Add functions directory to path\n",
    "sys.path.insert(0, str(Path.cwd() / 'functions'))\n",
    "\n",
    "from functions.ensemble_initialization import initialize_founder_model\n",
    "from functions.ensemble_hill_climbing import (\n",
    "    run_hill_climbing_iteration, update_temperature, compute_pipeline_hash, log_iteration\n",
    ")\n",
    "from functions.ensemble_parallel import train_candidates_parallel\n",
    "from functions.ensemble_config import (\n",
    "    BASE_TEMPERATURE, TEMPERATURE_DECAY, PLATEAU_ITERATIONS, TIMEOUT_THRESHOLD_SEC,\n",
    "    STAGE2_BATCH_SIZE_MODELS, STAGE2_EPOCHS, STAGE2_BATCH_SIZE, STAGE2_PATIENCE\n",
    ")\n",
    "from functions.ensemble_stage2_training import train_or_expand_stage2_model, save_ensemble_bundle\n",
    "from functions import ensemble_database\n",
    "\n",
    "# Get feature info\n",
    "numerical_features = X_train_diabetes.select_dtypes(include=[np.number]).columns.tolist()\n",
    "ordinal_features = ['education', 'income']\n",
    "nominal_features = [col for col in X_train_diabetes.columns if col not in numerical_features + ordinal_features]\n",
    "\n",
    "education_categories = ['Never attended school or only kindergarten', \n",
    "                       'Grades 1 through 8 (Elementary)', \n",
    "                       'Grades 9 through 11 (Some high school)', \n",
    "                       'Grade 12 or GED (High school graduate)', \n",
    "                       'College 1 year to 3 years (Some college or technical school)', \n",
    "                       'College 4 years or more (College graduate)']\n",
    "\n",
    "income_categories = ['Less than $10,000', '$10,000 to less than $15,000', \n",
    "                    '$15,000 to less than $20,000', '$20,000 to less than $25,000', \n",
    "                    '$25,000 to less than $35,000', '$35,000 to less than $50,000', \n",
    "                    '$50,000 to less than $75,000', '$75,000 or more']\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(MODELS_DIR / 'ensemble_training.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize ensemble\n",
    "logger.info(f\"Starting ensemble hill climbing at {datetime.now()}\")\n",
    "ensemble_models = []\n",
    "stage2_model = None\n",
    "temperature = BASE_TEMPERATURE\n",
    "best_ensemble_score = 0.0\n",
    "iteration = 0\n",
    "iterations_since_improvement = 0\n",
    "\n",
    "# Create batch directory\n",
    "ENSEMBLE_DIR = MODELS_DIR / f\"run_{RUN_ID}\" / \"ensemble_stage1_models\"\n",
    "ENSEMBLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize founder model (iteration 0)\n",
    "founder_score = initialize_founder_model(\n",
    "    X_train=X_train_diabetes,\n",
    "    y_train=y_train_diabetes,\n",
    "    X_val_s1=X_val_s1_diabetes,\n",
    "    y_val_s1=y_val_s1_diabetes,\n",
    "    X_val_s2=X_val_s2_diabetes,\n",
    "    y_val_s2=y_val_s2_diabetes,\n",
    "    base_preprocessor=base_preprocessor,\n",
    "    base_temperature=BASE_TEMPERATURE,\n",
    "    models_dir=ENSEMBLE_DIR,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "best_ensemble_score = founder_score\n",
    "iteration = 1  # Start hill climbing iterations after founder\n",
    "\n",
    "logger.info(f\"Founder baseline: {founder_score:.6f}\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"HILL CLIMBING OPTIMIZATION\")\n",
    "print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "# Main hill climbing loop (batched parallel)\n",
    "while iteration < MAX_ITERATIONS:\n",
    "    logger.info(f\"\\n{'=' * 80}\")\n",
    "    logger.info(f\"BATCH starting at iteration {iteration}\")\n",
    "    logger.info(f\"Current ensemble size: {len(ensemble_models)}\")\n",
    "    logger.info(f\"Best score: {best_ensemble_score:.6f}\")\n",
    "    logger.info(f\"Temperature: {temperature:.4f}\")\n",
    "    logger.info(f\"{'=' * 80}\")\n",
    "    \n",
    "    print(f\"\\nBatch starting at iteration {iteration} (ensemble size={len(ensemble_models)}, best={best_ensemble_score:.6f})\")\n",
    "    \n",
    "    # Train candidates in parallel\n",
    "    trained_candidates = train_candidates_parallel(\n",
    "        ensemble_models=ensemble_models,\n",
    "        stage2_model=stage2_model,\n",
    "        X_train=X_train_diabetes,\n",
    "        y_train=y_train_diabetes,\n",
    "        X_val_s1=X_val_s1_diabetes,\n",
    "        y_val_s1=y_val_s1_diabetes,\n",
    "        X_val_s2=X_val_s2_diabetes,\n",
    "        y_val_s2=y_val_s2_diabetes,\n",
    "        temperature=temperature,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        n_workers=N_WORKERS,\n",
    "        timeout_sec=TIMEOUT_THRESHOLD_SEC,\n",
    "        base_preprocessor=base_preprocessor,\n",
    "        numerical_features=numerical_features,\n",
    "        ordinal_features=ordinal_features,\n",
    "        nominal_features=nominal_features,\n",
    "        education_categories=education_categories,\n",
    "        income_categories=income_categories,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # Process results\n",
    "    accepted_count = 0\n",
    "    for result in trained_candidates:\n",
    "        current_iter = iteration\n",
    "        iteration += 1  # Increment for next candidate\n",
    "        \n",
    "        if result['timeout']:\n",
    "            logger.info(f\"\\nIteration {current_iter}: TIMEOUT (>{TIMEOUT_THRESHOLD_SEC}s)\")\n",
    "            \n",
    "            # Log timeout entry\n",
    "            log_iteration(\n",
    "                iteration=current_iter,\n",
    "                accepted=False,\n",
    "                rejection_reason='timeout',\n",
    "                pipeline_hash='timeout',\n",
    "                stage1_val_auc=0.0,\n",
    "                stage2_val_auc=0.0,\n",
    "                ensemble_size=len(ensemble_models),\n",
    "                diversity_score=0.0,\n",
    "                temperature=temperature,\n",
    "                metadata={'classifier_type': 'timeout', 'transformers_used': []},\n",
    "                ensemble_id=f\"iter_{current_iter}\",\n",
    "                timeout=True\n",
    "            )\n",
    "            continue\n",
    "        \n",
    "        # Extract results\n",
    "        fitted_pipeline = result['fitted_pipeline']\n",
    "        metadata = result['metadata']\n",
    "        val_auc_s1 = result['val_auc_s1']\n",
    "        candidate_score = result['candidate_score']\n",
    "        diversity_score = result['diversity_score']\n",
    "        pipeline_hash = result['pipeline_hash']\n",
    "        accept = result['accept']\n",
    "        reason = result['reason']\n",
    "        training_memory_mb = result['training_memory_mb']\n",
    "        training_time_sec = result['training_time_sec']\n",
    "        stage2_memory_mb = result['stage2_memory_mb']\n",
    "        stage2_time_sec = result['stage2_time_sec']\n",
    "        \n",
    "        # Determine logged score for database\n",
    "        logged_ensemble_score = candidate_score if accept else best_ensemble_score\n",
    "        \n",
    "        # Log to database\n",
    "        log_iteration(\n",
    "            iteration=current_iter,\n",
    "            accepted=accept,\n",
    "            rejection_reason=reason,\n",
    "            pipeline_hash=pipeline_hash,\n",
    "            stage1_val_auc=val_auc_s1,\n",
    "            stage2_val_auc=logged_ensemble_score,\n",
    "            ensemble_size=len(ensemble_models) + 1 if accept else len(ensemble_models),\n",
    "            diversity_score=diversity_score,\n",
    "            temperature=temperature,\n",
    "            metadata=metadata,\n",
    "            ensemble_id=f\"iter_{current_iter}\",\n",
    "            training_memory_mb=training_memory_mb,\n",
    "            stage2_memory_mb=stage2_memory_mb,\n",
    "            training_time_sec=training_time_sec,\n",
    "            stage2_time_sec=stage2_time_sec,\n",
    "            timeout=False\n",
    "        )\n",
    "        \n",
    "        # Update ensemble if accepted\n",
    "        if accept:\n",
    "            accepted_count += 1\n",
    "            ensemble_models.append(fitted_pipeline)\n",
    "            \n",
    "            # Save model\n",
    "            model_path = ENSEMBLE_DIR / f'model_{current_iter}.joblib'\n",
    "            joblib.dump(fitted_pipeline, model_path)\n",
    "            \n",
    "            # Check if we should train/retrain stage 2 DNN\n",
    "            if len(ensemble_models) % STAGE2_BATCH_SIZE_MODELS == 0 and len(ensemble_models) > 0:\n",
    "\n",
    "                stage2_model, final_score, stage2_memory_mb, stage2_time_sec, stage2_tp, stage2_fp, stage2_tn, stage2_fn = train_or_expand_stage2_model(\n",
    "                    ensemble_models, stage2_model, X_val_s1, y_val_s1, X_val_s2, y_val_s2,\n",
    "                    STAGE2_EPOCHS, STAGE2_BATCH_SIZE, STAGE2_PATIENCE, current_iter\n",
    "                )\n",
    "                \n",
    "                # Log DNN retrain score as separate entry\n",
    "                logger.info(f\"\\n{'=' * 80}\")\n",
    "                logger.info(f\"DNN RETRAINED at {len(ensemble_models)} models | Final ensemble AUC: {final_score:.6f}\")\n",
    "                logger.info(f\"Memory: {stage2_memory_mb:.1f}MB, Time: {stage2_time_sec:.1f}s\")\n",
    "                logger.info(f\"{'=' * 80}\")\n",
    "                \n",
    "                print(f\"\\n{'=' * 80}\")\n",
    "                print(f\"DNN RETRAINED at {len(ensemble_models)} models | Final ensemble AUC: {final_score:.6f}\")\n",
    "                print(f\"{'=' * 80}\")\n",
    "                \n",
    "                log_iteration(\n",
    "                    iteration=current_iter,\n",
    "                    accepted=True,\n",
    "                    rejection_reason=f\"dnn_retrain_batch_{len(ensemble_models)}\",\n",
    "                    pipeline_hash=f\"dnn_retrain_{len(ensemble_models)}\",\n",
    "                    stage1_val_auc=val_auc_s1,\n",
    "                    stage2_val_auc=final_score,\n",
    "                    ensemble_size=len(ensemble_models),\n",
    "                    diversity_score=diversity_score,\n",
    "                    temperature=temperature,\n",
    "                    metadata={'classifier_type': 'dnn_retrain', 'transformers_used': []},\n",
    "                    ensemble_id=f\"dnn_retrain_{len(ensemble_models)}\",\n",
    "                    training_memory_mb=None,\n",
    "                    stage2_memory_mb=stage2_memory_mb,\n",
    "                    training_time_sec=None,\n",
    "                    stage2_time_sec=stage2_time_sec,\n",
    "                    timeout=False,\n",
    "                    stage2_tp=stage2_tp,\n",
    "                    stage2_fp=stage2_fp,\n",
    "                    stage2_tn=stage2_tn,\n",
    "                    stage2_fn=stage2_fn\n",
    "                )\n",
    "                \n",
    "                # Save ensemble bundle checkpoint\n",
    "                save_ensemble_bundle(\n",
    "                    ensemble_models, stage2_model, best_ensemble_score, current_iter,\n",
    "                    MODELS_DIR, RANDOM_STATE, BATCH_SIZE, N_WORKERS, base_preprocessor,\n",
    "                    numerical_features, ordinal_features, nominal_features,\n",
    "                    education_categories, income_categories\n",
    "                )\n",
    "            \n",
    "            # Check if this is the best score\n",
    "            if candidate_score > best_ensemble_score:\n",
    "                logger.info(f\"    NEW BEST: {candidate_score:.6f} (Δ={candidate_score - best_ensemble_score:.6f})\")\n",
    "                best_ensemble_score = candidate_score\n",
    "                iterations_since_improvement = 0\n",
    "            else:\n",
    "                iterations_since_improvement += 1\n",
    "        else:\n",
    "            iterations_since_improvement += 1\n",
    "        \n",
    "        # Update temperature\n",
    "        temperature = update_temperature(\n",
    "            iteration=current_iter,\n",
    "            acceptance_history=[accept],\n",
    "            current_temperature=temperature,\n",
    "            base_temperature=BASE_TEMPERATURE,\n",
    "            decay_rate=TEMPERATURE_DECAY\n",
    "        )\n",
    "    \n",
    "    # Log batch summary\n",
    "    logger.info(f\"Batch summary: {accepted_count}/{len(trained_candidates)} accepted, \"\n",
    "               f\"Ensemble size now {len(ensemble_models)}, Best score {best_ensemble_score:.6f}\")\n",
    "    \n",
    "    # Move to next batch\n",
    "    iteration += len(trained_candidates)\n",
    "    \n",
    "    # Check termination\n",
    "    if iterations_since_improvement >= PLATEAU_ITERATIONS:\n",
    "        logger.info(f\"TERMINATING: No improvement for {PLATEAU_ITERATIONS} iterations\")\n",
    "        print(f\"TERMINATING: No improvement for {PLATEAU_ITERATIONS} iterations\")\n",
    "        break\n",
    "\n",
    "# Calculate final acceptance rate and timeout rate\n",
    "conn = ensemble_database.sqlite3.connect(ensemble_database.DB_PATH)\n",
    "acceptance_stats = conn.execute(\"SELECT COUNT(*) as total, SUM(accepted) as accepted FROM ensemble_log WHERE iteration_num > 0\").fetchone()\n",
    "timeout_stats = conn.execute(\"SELECT SUM(timeout) as timeouts FROM ensemble_log WHERE iteration_num > 0\").fetchone()\n",
    "conn.close()\n",
    "\n",
    "acceptance_rate = acceptance_stats[1] / acceptance_stats[0] if acceptance_stats[0] > 0 else 0.0\n",
    "timeout_rate = timeout_stats[0] / acceptance_stats[0] if acceptance_stats[0] > 0 else 0.0\n",
    "\n",
    "logger.info(\"\\n\" + \"=\" * 80)\n",
    "logger.info(\"TRAINING COMPLETE\")\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(f\"Total iterations: {iteration - 1}\")\n",
    "logger.info(f\"Final ensemble size: {len(ensemble_models)}\")\n",
    "logger.info(f\"Best ensemble AUC: {best_ensemble_score:.6f}\")\n",
    "logger.info(f\"Acceptance rate: {acceptance_rate:.1%}\")\n",
    "logger.info(f\"Timeout rate: {timeout_rate:.1%}\")\n",
    "logger.info(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"Total iterations: {iteration - 1}\")\n",
    "print(f\"Final ensemble size: {len(ensemble_models)}\")\n",
    "print(f\"Best ensemble AUC: {best_ensemble_score:.6f}\")\n",
    "print(f\"Acceptance rate: {acceptance_rate:.1%}\")\n",
    "print(f\"Timeout rate: {timeout_rate:.1%}\")\n",
    "print(f\"{'=' * 80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e4cad",
   "metadata": {},
   "source": [
    "## Save final checkpoint and bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f505a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final checkpoint\n",
    "save_checkpoint(\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    ensemble_models=ensemble_models,\n",
    "    stage2_model=stage2_model,\n",
    "    iteration=iteration - 1,\n",
    "    temperature=temperature,\n",
    "    best_score=best_ensemble_score,\n",
    "    acceptance_history=[],\n",
    "    metadata={\n",
    "        'total_iterations': iteration,\n",
    "        'final_ensemble_size': len(ensemble_models),\n",
    "        'acceptance_rate': acceptance_rate,\n",
    "        'best_score': best_ensemble_score,\n",
    "        'parallel_batch_size': BATCH_SIZE,\n",
    "        'n_workers': N_WORKERS\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = MODELS_DIR / 'ensemble_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'ensemble_size': len(ensemble_models),\n",
    "        'total_iterations': iteration,\n",
    "        'best_score': best_ensemble_score,\n",
    "        'acceptance_rate': acceptance_rate,\n",
    "        'training_completed': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'parallel_batch_size': BATCH_SIZE,\n",
    "        'n_workers': N_WORKERS\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nCheckpoint saved: {CHECKPOINT_PATH}\")\n",
    "print(f\"Metadata saved: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final ensemble bundle for Kaggle\n",
    "ensemble_bundle_path = MODELS_DIR / 'ensemble_bundle.joblib'\n",
    "\n",
    "ensemble_bundle = {\n",
    "    'ensemble_models': ensemble_models,\n",
    "    'stage2_model': stage2_model,\n",
    "    'metadata': {\n",
    "        'ensemble_size': len(ensemble_models),\n",
    "        'total_iterations': iteration,\n",
    "        'best_score': best_ensemble_score,\n",
    "        'acceptance_rate': acceptance_rate,\n",
    "        'training_completed': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'parallel_batch_size': BATCH_SIZE,\n",
    "        'n_workers': N_WORKERS\n",
    "    },\n",
    "    'base_preprocessor': base_preprocessor,\n",
    "    'feature_info': {\n",
    "        'numerical_features': numerical_features,\n",
    "        'ordinal_features': ordinal_features,\n",
    "        'nominal_features': nominal_features,\n",
    "        'education_categories': education_categories,\n",
    "        'income_categories': income_categories\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(ensemble_bundle, ensemble_bundle_path, compress=3)\n",
    "\n",
    "print(f\"\\nFinal ensemble bundle saved: {ensemble_bundle_path}\")\n",
    "print(f\"File size: {ensemble_bundle_path.stat().st_size / (1024**2):.1f} MB\")\n",
    "print(f\"\\nTo load on Kaggle:\")\n",
    "print(f\"  ensemble_bundle = joblib.load('ensemble_bundle.joblib')\")\n",
    "print(f\"  ensemble_models = ensemble_bundle['ensemble_models']\")\n",
    "print(f\"  stage2_model = ensemble_bundle['stage2_model']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wrapper class\n",
    "sys.path.insert(0, str(MODELS_BASE_DIR))\n",
    "\n",
    "# Create wrapped model\n",
    "wrapped_model = EnsembleClassifier(\n",
    "    ensemble_models=ensemble_models,\n",
    "    stage2_model=stage2_model,\n",
    "    aggregation='mean'  # Fallback if stage2_model is None\n",
    ")\n",
    "\n",
    "# Save as single joblib file\n",
    "wrapped_model_path = MODELS_DIR / 'ensemble_model.joblib'\n",
    "joblib.dump(wrapped_model, wrapped_model_path, compress=3)\n",
    "\n",
    "print(f\"\\nWrapped ensemble model saved: {wrapped_model_path}\")\n",
    "print(f\"File size: {wrapped_model_path.stat().st_size / (1024**2):.1f} MB\")\n",
    "print(f\"\\nModel info: {wrapped_model}\")\n",
    "print(f\"\\nTo use on Kaggle:\")\n",
    "print(f\"  1. Upload to Kaggle dataset:\")\n",
    "print(f\"     - {wrapped_model_path.name}\")\n",
    "print(f\"     - {MODELS_BASE_DIR / 'ensemble_classifier.py'}\")\n",
    "print(f\"  2. In inference notebook:\")\n",
    "print(f\"     from ensemble_classifier import EnsembleClassifier\")\n",
    "print(f\"     model = joblib.load('ensemble_model.joblib')\")\n",
    "print(f\"     predictions = model.predict(test_df)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7f59f",
   "metadata": {},
   "source": [
    "## Create wrapped ensemble model for Kaggle\n",
    "\n",
    "Create a sklearn-compatible wrapper that bundles the entire ensemble into a single classifier.\n",
    "This makes inference identical to the logistic regression workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab336e9",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"ENSEMBLE TRAINING SUMMARY\")\n",
    "print(f\"{'=' * 80}\")\n",
    "print(f\"\\nFinal Statistics:\")\n",
    "print(f\"  Ensemble size: {len(ensemble_models)}\")\n",
    "print(f\"  Best validation AUC: {best_ensemble_score:.6f}\")\n",
    "print(f\"  Total iterations: {iteration}\")\n",
    "print(f\"  Acceptance rate: {acceptance_rate:.1%}\")\n",
    "print(f\"  Parallel configuration: {BATCH_SIZE} candidates, {N_WORKERS} workers\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  Database: {ensemble_database.DB_PATH}\")\n",
    "print(f\"  Models: {ENSEMBLE_DIR}\")\n",
    "print(f\"  Checkpoint: {CHECKPOINT_PATH}\")\n",
    "print(f\"  Metadata: {metadata_path}\")\n",
    "print(f\"  Bundle: {ensemble_bundle_path}\")\n",
    "print(f\"\\n{'=' * 80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
